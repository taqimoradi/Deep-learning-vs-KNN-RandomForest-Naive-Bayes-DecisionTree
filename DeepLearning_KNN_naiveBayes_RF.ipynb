{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given dataset contains details about organic chemical compounds including their chemical features, isomeric conformation, names and the classes in which they are classified so for classification I use both deep learning and sklearn(KNN , decision Tree , Naive Bayes , Random forest , Logistic regression) aproache and for each algorithm I check the confusion_matrix ,F1_ score , Accuracy score  , precision_score , recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the libraris for data preprocessing and machine learning algorithm implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from  collections import Counter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data set\n",
    "df = pd.read_csv('musk_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>conformation_name</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>...</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "      <th>f161</th>\n",
       "      <th>f162</th>\n",
       "      <th>f163</th>\n",
       "      <th>f164</th>\n",
       "      <th>f165</th>\n",
       "      <th>f166</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+1</td>\n",
       "      <td>46</td>\n",
       "      <td>-108</td>\n",
       "      <td>-60</td>\n",
       "      <td>-69</td>\n",
       "      <td>-117</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>-308</td>\n",
       "      <td>52</td>\n",
       "      <td>-7</td>\n",
       "      <td>39</td>\n",
       "      <td>126</td>\n",
       "      <td>156</td>\n",
       "      <td>-50</td>\n",
       "      <td>-112</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+10</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-6</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-59</td>\n",
       "      <td>-2</td>\n",
       "      <td>52</td>\n",
       "      <td>103</td>\n",
       "      <td>136</td>\n",
       "      <td>169</td>\n",
       "      <td>-61</td>\n",
       "      <td>-136</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+11</td>\n",
       "      <td>46</td>\n",
       "      <td>-194</td>\n",
       "      <td>-145</td>\n",
       "      <td>28</td>\n",
       "      <td>-117</td>\n",
       "      <td>73</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-134</td>\n",
       "      <td>-154</td>\n",
       "      <td>57</td>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "      <td>165</td>\n",
       "      <td>-67</td>\n",
       "      <td>-145</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+12</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>136</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+13</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>137</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID molecule_name conformation_name  f1   f2   f3  f4   f5  f6  f7  ...  \\\n",
       "0   1      MUSK-211           211_1+1  46 -108  -60 -69 -117  49  38  ...   \n",
       "1   2      MUSK-211          211_1+10  41 -188 -145  22 -117  -6  57  ...   \n",
       "2   3      MUSK-211          211_1+11  46 -194 -145  28 -117  73  57  ...   \n",
       "3   4      MUSK-211          211_1+12  41 -188 -145  22 -117  -7  57  ...   \n",
       "4   5      MUSK-211          211_1+13  41 -188 -145  22 -117  -7  57  ...   \n",
       "\n",
       "   f158  f159  f160  f161  f162  f163  f164  f165  f166  class  \n",
       "0  -308    52    -7    39   126   156   -50  -112    96      1  \n",
       "1   -59    -2    52   103   136   169   -61  -136    79      1  \n",
       "2  -134  -154    57   143   142   165   -67  -145    39      1  \n",
       "3   -60    -4    52   104   136   168   -60  -135    80      1  \n",
       "4   -60    -4    52   104   137   168   -60  -135    80      1  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the information about the data set , that how many rows ans how many columns have \n",
    "and what are the data types of each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6598 entries, 0 to 6597\n",
      "Columns: 170 entries, ID to class\n",
      "dtypes: int64(168), object(2)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statistical describtion of data which have numeric data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "      <th>f161</th>\n",
       "      <th>f162</th>\n",
       "      <th>f163</th>\n",
       "      <th>f164</th>\n",
       "      <th>f165</th>\n",
       "      <th>f166</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6598.00000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3299.50000</td>\n",
       "      <td>58.945135</td>\n",
       "      <td>-119.128524</td>\n",
       "      <td>-73.146560</td>\n",
       "      <td>-0.628372</td>\n",
       "      <td>-103.533495</td>\n",
       "      <td>18.359806</td>\n",
       "      <td>-14.108821</td>\n",
       "      <td>-1.858290</td>\n",
       "      <td>-86.003031</td>\n",
       "      <td>...</td>\n",
       "      <td>-184.798272</td>\n",
       "      <td>-75.795696</td>\n",
       "      <td>-26.073204</td>\n",
       "      <td>64.616702</td>\n",
       "      <td>112.037739</td>\n",
       "      <td>201.760230</td>\n",
       "      <td>-47.488330</td>\n",
       "      <td>-150.259927</td>\n",
       "      <td>41.770233</td>\n",
       "      <td>0.154138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1904.82287</td>\n",
       "      <td>53.249007</td>\n",
       "      <td>90.813375</td>\n",
       "      <td>67.956235</td>\n",
       "      <td>80.444617</td>\n",
       "      <td>64.387559</td>\n",
       "      <td>80.593655</td>\n",
       "      <td>115.315673</td>\n",
       "      <td>90.372537</td>\n",
       "      <td>108.326676</td>\n",
       "      <td>...</td>\n",
       "      <td>107.819514</td>\n",
       "      <td>127.861271</td>\n",
       "      <td>69.727964</td>\n",
       "      <td>100.861935</td>\n",
       "      <td>72.835040</td>\n",
       "      <td>59.526751</td>\n",
       "      <td>55.069365</td>\n",
       "      <td>76.019023</td>\n",
       "      <td>94.116085</td>\n",
       "      <td>0.361108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>-199.000000</td>\n",
       "      <td>-167.000000</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>-118.000000</td>\n",
       "      <td>-183.000000</td>\n",
       "      <td>-171.000000</td>\n",
       "      <td>-225.000000</td>\n",
       "      <td>-245.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-328.000000</td>\n",
       "      <td>-219.000000</td>\n",
       "      <td>-136.000000</td>\n",
       "      <td>-120.000000</td>\n",
       "      <td>-69.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>-289.000000</td>\n",
       "      <td>-428.000000</td>\n",
       "      <td>-471.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1650.25000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>-193.000000</td>\n",
       "      <td>-137.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>-117.000000</td>\n",
       "      <td>-28.000000</td>\n",
       "      <td>-159.000000</td>\n",
       "      <td>-85.000000</td>\n",
       "      <td>-217.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-272.000000</td>\n",
       "      <td>-205.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>-68.000000</td>\n",
       "      <td>-179.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3299.50000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>-149.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-117.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-234.000000</td>\n",
       "      <td>-131.000000</td>\n",
       "      <td>-21.000000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-150.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4948.75000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>-116.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>-21.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>-120.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6598.00000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID           f1           f2           f3           f4  \\\n",
       "count  6598.00000  6598.000000  6598.000000  6598.000000  6598.000000   \n",
       "mean   3299.50000    58.945135  -119.128524   -73.146560    -0.628372   \n",
       "std    1904.82287    53.249007    90.813375    67.956235    80.444617   \n",
       "min       1.00000   -31.000000  -199.000000  -167.000000  -114.000000   \n",
       "25%    1650.25000    37.000000  -193.000000  -137.000000   -70.000000   \n",
       "50%    3299.50000    44.000000  -149.000000   -99.000000   -25.000000   \n",
       "75%    4948.75000    53.000000   -95.000000   -19.000000    42.000000   \n",
       "max    6598.00000   292.000000    95.000000    81.000000   161.000000   \n",
       "\n",
       "                f5           f6           f7           f8           f9  ...  \\\n",
       "count  6598.000000  6598.000000  6598.000000  6598.000000  6598.000000  ...   \n",
       "mean   -103.533495    18.359806   -14.108821    -1.858290   -86.003031  ...   \n",
       "std      64.387559    80.593655   115.315673    90.372537   108.326676  ...   \n",
       "min    -118.000000  -183.000000  -171.000000  -225.000000  -245.000000  ...   \n",
       "25%    -117.000000   -28.000000  -159.000000   -85.000000  -217.000000  ...   \n",
       "50%    -117.000000    33.000000    27.000000    19.000000   -40.000000  ...   \n",
       "75%    -116.000000    74.000000    57.000000    61.000000   -21.000000  ...   \n",
       "max     325.000000   200.000000   220.000000   320.000000   147.000000  ...   \n",
       "\n",
       "              f158         f159         f160         f161         f162  \\\n",
       "count  6598.000000  6598.000000  6598.000000  6598.000000  6598.000000   \n",
       "mean   -184.798272   -75.795696   -26.073204    64.616702   112.037739   \n",
       "std     107.819514   127.861271    69.727964   100.861935    72.835040   \n",
       "min    -328.000000  -219.000000  -136.000000  -120.000000   -69.000000   \n",
       "25%    -272.000000  -205.000000   -70.000000   -18.000000    71.000000   \n",
       "50%    -234.000000  -131.000000   -21.000000    61.500000   107.000000   \n",
       "75%     -80.000000    52.000000     9.000000   149.000000   129.000000   \n",
       "max      94.000000   179.000000   192.000000   411.000000   355.000000   \n",
       "\n",
       "              f163         f164         f165         f166        class  \n",
       "count  6598.000000  6598.000000  6598.000000  6598.000000  6598.000000  \n",
       "mean    201.760230   -47.488330  -150.259927    41.770233     0.154138  \n",
       "std      59.526751    55.069365    76.019023    94.116085     0.361108  \n",
       "min      73.000000  -289.000000  -428.000000  -471.000000     0.000000  \n",
       "25%     166.000000   -68.000000  -179.000000    -9.000000     0.000000  \n",
       "50%     191.000000   -60.000000  -150.000000    27.000000     0.000000  \n",
       "75%     215.000000   -45.000000  -120.000000   119.000000     0.000000  \n",
       "max     625.000000   295.000000   168.000000   367.000000     1.000000  \n",
       "\n",
       "[8 rows x 168 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describtion of data which are in string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>conformation_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6598</td>\n",
       "      <td>6598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>102</td>\n",
       "      <td>6598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NON-MUSK-j146</td>\n",
       "      <td>252_1+172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        molecule_name conformation_name\n",
       "count            6598              6598\n",
       "unique            102              6598\n",
       "top     NON-MUSK-j146         252_1+172\n",
       "freq             1044                 1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "molecule_name        0\n",
       "conformation_name    0\n",
       "f1                   0\n",
       "f2                   0\n",
       "f3                   0\n",
       "f4                   0\n",
       "f5                   0\n",
       "f6                   0\n",
       "f7                   0\n",
       "f8                   0\n",
       "f9                   0\n",
       "f10                  0\n",
       "f11                  0\n",
       "f12                  0\n",
       "f13                  0\n",
       "f14                  0\n",
       "f15                  0\n",
       "f16                  0\n",
       "f17                  0\n",
       "f18                  0\n",
       "f19                  0\n",
       "f20                  0\n",
       "f21                  0\n",
       "f22                  0\n",
       "f23                  0\n",
       "f24                  0\n",
       "f25                  0\n",
       "f26                  0\n",
       "f27                  0\n",
       "                    ..\n",
       "f138                 0\n",
       "f139                 0\n",
       "f140                 0\n",
       "f141                 0\n",
       "f142                 0\n",
       "f143                 0\n",
       "f144                 0\n",
       "f145                 0\n",
       "f146                 0\n",
       "f147                 0\n",
       "f148                 0\n",
       "f149                 0\n",
       "f150                 0\n",
       "f151                 0\n",
       "f152                 0\n",
       "f153                 0\n",
       "f154                 0\n",
       "f155                 0\n",
       "f156                 0\n",
       "f157                 0\n",
       "f158                 0\n",
       "f159                 0\n",
       "f160                 0\n",
       "f161                 0\n",
       "f162                 0\n",
       "f163                 0\n",
       "f164                 0\n",
       "f165                 0\n",
       "f166                 0\n",
       "class                0\n",
       "Length: 170, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding the correlation of each attributes with the classification target so that the correlation value are in the range of \n",
    "-1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    1.000000\n",
       "f26      0.163585\n",
       "f118     0.154010\n",
       "f9       0.147509\n",
       "f108     0.147264\n",
       "f77      0.145602\n",
       "f86      0.143419\n",
       "f48      0.138190\n",
       "f95      0.137931\n",
       "f53      0.135453\n",
       "f139     0.129267\n",
       "f119     0.127419\n",
       "f52      0.125470\n",
       "f81      0.123262\n",
       "f114     0.121631\n",
       "f113     0.118256\n",
       "f17      0.117892\n",
       "f7       0.113093\n",
       "f22      0.107039\n",
       "f82      0.104050\n",
       "f23      0.103916\n",
       "f112     0.098047\n",
       "f160     0.097957\n",
       "f56      0.091634\n",
       "f98      0.084038\n",
       "f21      0.082980\n",
       "f34      0.082844\n",
       "f57      0.082780\n",
       "f127     0.078154\n",
       "f128     0.069481\n",
       "           ...   \n",
       "f19     -0.175573\n",
       "f54     -0.179462\n",
       "f125    -0.179467\n",
       "f11     -0.184796\n",
       "f103    -0.190685\n",
       "f46     -0.191578\n",
       "f106    -0.193720\n",
       "f80     -0.194174\n",
       "f104    -0.195028\n",
       "f8      -0.201554\n",
       "f91     -0.205506\n",
       "f44     -0.206215\n",
       "f110    -0.206606\n",
       "f74     -0.207552\n",
       "f105    -0.208192\n",
       "f111    -0.208512\n",
       "f15     -0.210261\n",
       "f45     -0.210292\n",
       "f78     -0.210497\n",
       "f135    -0.210645\n",
       "f49     -0.210816\n",
       "f109    -0.211642\n",
       "f163    -0.217481\n",
       "f14     -0.218065\n",
       "f96     -0.220994\n",
       "f124    -0.224108\n",
       "f126    -0.261096\n",
       "f36     -0.264802\n",
       "f132    -0.270949\n",
       "ID      -0.625410\n",
       "Name: class, Length: 168, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix['class'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify the feature(x whihc are independant) and target(y which is dependent on values of x) variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[: , :-1]\n",
    "X =X.iloc[: , 3:]\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f157</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "      <th>f161</th>\n",
       "      <th>f162</th>\n",
       "      <th>f163</th>\n",
       "      <th>f164</th>\n",
       "      <th>f165</th>\n",
       "      <th>f166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>-108</td>\n",
       "      <td>-60</td>\n",
       "      <td>-69</td>\n",
       "      <td>-117</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>-161</td>\n",
       "      <td>-8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-244</td>\n",
       "      <td>-308</td>\n",
       "      <td>52</td>\n",
       "      <td>-7</td>\n",
       "      <td>39</td>\n",
       "      <td>126</td>\n",
       "      <td>156</td>\n",
       "      <td>-50</td>\n",
       "      <td>-112</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-6</td>\n",
       "      <td>57</td>\n",
       "      <td>-171</td>\n",
       "      <td>-39</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-235</td>\n",
       "      <td>-59</td>\n",
       "      <td>-2</td>\n",
       "      <td>52</td>\n",
       "      <td>103</td>\n",
       "      <td>136</td>\n",
       "      <td>169</td>\n",
       "      <td>-61</td>\n",
       "      <td>-136</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>-194</td>\n",
       "      <td>-145</td>\n",
       "      <td>28</td>\n",
       "      <td>-117</td>\n",
       "      <td>73</td>\n",
       "      <td>57</td>\n",
       "      <td>-168</td>\n",
       "      <td>-39</td>\n",
       "      <td>-22</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-134</td>\n",
       "      <td>-154</td>\n",
       "      <td>57</td>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "      <td>165</td>\n",
       "      <td>-67</td>\n",
       "      <td>-145</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>-170</td>\n",
       "      <td>-39</td>\n",
       "      <td>-99</td>\n",
       "      <td>...</td>\n",
       "      <td>-236</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>136</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-7</td>\n",
       "      <td>57</td>\n",
       "      <td>-170</td>\n",
       "      <td>-39</td>\n",
       "      <td>-99</td>\n",
       "      <td>...</td>\n",
       "      <td>-236</td>\n",
       "      <td>-60</td>\n",
       "      <td>-4</td>\n",
       "      <td>52</td>\n",
       "      <td>104</td>\n",
       "      <td>137</td>\n",
       "      <td>168</td>\n",
       "      <td>-60</td>\n",
       "      <td>-135</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1   f2   f3  f4   f5  f6  f7   f8  f9  f10  ...  f157  f158  f159  f160  \\\n",
       "0  46 -108  -60 -69 -117  49  38 -161  -8    5  ...  -244  -308    52    -7   \n",
       "1  41 -188 -145  22 -117  -6  57 -171 -39 -100  ...  -235   -59    -2    52   \n",
       "2  46 -194 -145  28 -117  73  57 -168 -39  -22  ...  -238  -134  -154    57   \n",
       "3  41 -188 -145  22 -117  -7  57 -170 -39  -99  ...  -236   -60    -4    52   \n",
       "4  41 -188 -145  22 -117  -7  57 -170 -39  -99  ...  -236   -60    -4    52   \n",
       "\n",
       "   f161  f162  f163  f164  f165  f166  \n",
       "0    39   126   156   -50  -112    96  \n",
       "1   103   136   169   -61  -136    79  \n",
       "2   143   142   165   -67  -145    39  \n",
       "3   104   136   168   -60  -135    80  \n",
       "4   104   137   168   -60  -135    80  \n",
       "\n",
       "[5 rows x 166 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1017, 0: 5581})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using sklearn we can split the data into traning and test part . that from over all data 20% are for testing and 80% are for \n",
    "traning.\n",
    "if we check the data it is not a normal(standard) data so for the purpose of gething accurate result we have to standardize data using standard scaler or any other methods . In hereI use Standad Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MORADI\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\MORADI\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\MORADI\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementation of LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MORADI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix: [[1096   21]\n",
      " [  48  155]]\n",
      "F1_ score : 0.8179419525065964\n",
      "Accuracy score: 0.9477272727272728\n",
      "precision_score: 0.8806818181818182\n",
      "recall_score: 0.7635467980295566\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predict = classifier.predict(X_test)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(\"confusion_matrix:\",confusion_matrix(y_test , y_predict))\n",
    "print(\"F1_score :\",metrics.f1_score(y_test , y_predict))\n",
    "print(\"Accuracy score:\",metrics.accuracy_score(y_test , y_predict))\n",
    "print(\"precision_score:\",metrics.precision_score(y_test , y_predict))\n",
    "print(\"recall_score:\",metrics.recall_score(y_test , y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5278, 166)\n",
      "(1320, 166)\n",
      "(5278,)\n",
      "(1320,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining the model structure for deep learning implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]  # Number of features\n",
    "# input_dim\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                1670      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,681\n",
      "Trainable params: 1,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fiting the the deep learning algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5278 samples, validate on 1320 samples\n",
      "Epoch 1/100\n",
      "5278/5278 [==============================] - 1s 130us/step - loss: 0.2883 - accuracy: 0.8941 - val_loss: 0.2116 - val_accuracy: 0.9174\n",
      "Epoch 2/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.1794 - accuracy: 0.9326 - val_loss: 0.1646 - val_accuracy: 0.9311\n",
      "Epoch 3/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 0.1392 - accuracy: 0.9441 - val_loss: 0.1300 - val_accuracy: 0.9462\n",
      "Epoch 4/100\n",
      "5278/5278 [==============================] - 0s 71us/step - loss: 0.1129 - accuracy: 0.9549 - val_loss: 0.1113 - val_accuracy: 0.9500\n",
      "Epoch 5/100\n",
      "5278/5278 [==============================] - 0s 71us/step - loss: 0.0950 - accuracy: 0.9629 - val_loss: 0.0947 - val_accuracy: 0.9591\n",
      "Epoch 6/100\n",
      "5278/5278 [==============================] - 0s 76us/step - loss: 0.0814 - accuracy: 0.9676 - val_loss: 0.0862 - val_accuracy: 0.9659\n",
      "Epoch 7/100\n",
      "5278/5278 [==============================] - 0s 75us/step - loss: 0.0721 - accuracy: 0.9723 - val_loss: 0.0765 - val_accuracy: 0.9727\n",
      "Epoch 8/100\n",
      "5278/5278 [==============================] - 0s 77us/step - loss: 0.0634 - accuracy: 0.9761 - val_loss: 0.0714 - val_accuracy: 0.9727\n",
      "Epoch 9/100\n",
      "5278/5278 [==============================] - 0s 80us/step - loss: 0.0573 - accuracy: 0.9790 - val_loss: 0.0642 - val_accuracy: 0.9735\n",
      "Epoch 10/100\n",
      "5278/5278 [==============================] - 0s 71us/step - loss: 0.0508 - accuracy: 0.9831 - val_loss: 0.0567 - val_accuracy: 0.9795\n",
      "Epoch 11/100\n",
      "5278/5278 [==============================] - 0s 76us/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0575 - val_accuracy: 0.9773\n",
      "Epoch 12/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 0.0508 - val_accuracy: 0.9773\n",
      "Epoch 13/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 0.0388 - accuracy: 0.9881 - val_loss: 0.0486 - val_accuracy: 0.9811\n",
      "Epoch 14/100\n",
      "5278/5278 [==============================] - 0s 74us/step - loss: 0.0356 - accuracy: 0.9894 - val_loss: 0.0450 - val_accuracy: 0.9841\n",
      "Epoch 15/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0404 - val_accuracy: 0.9826\n",
      "Epoch 16/100\n",
      "5278/5278 [==============================] - 0s 71us/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 0.0398 - val_accuracy: 0.9841\n",
      "Epoch 17/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.0389 - val_accuracy: 0.9871\n",
      "Epoch 18/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.0330 - val_accuracy: 0.9871\n",
      "Epoch 19/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 0.0336 - val_accuracy: 0.9864\n",
      "Epoch 20/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0209 - accuracy: 0.9955 - val_loss: 0.0313 - val_accuracy: 0.9871\n",
      "Epoch 21/100\n",
      "5278/5278 [==============================] - 0s 75us/step - loss: 0.0191 - accuracy: 0.9964 - val_loss: 0.0326 - val_accuracy: 0.9879\n",
      "Epoch 22/100\n",
      "5278/5278 [==============================] - 0s 80us/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.0295 - val_accuracy: 0.9894\n",
      "Epoch 23/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 0.0159 - accuracy: 0.9972 - val_loss: 0.0280 - val_accuracy: 0.9902\n",
      "Epoch 24/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 0.0148 - accuracy: 0.9979 - val_loss: 0.0271 - val_accuracy: 0.9871\n",
      "Epoch 25/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0134 - accuracy: 0.9977 - val_loss: 0.0258 - val_accuracy: 0.9909\n",
      "Epoch 26/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.0259 - val_accuracy: 0.9902\n",
      "Epoch 27/100\n",
      "5278/5278 [==============================] - 0s 76us/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.0239 - val_accuracy: 0.9924\n",
      "Epoch 28/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.0231 - val_accuracy: 0.9924\n",
      "Epoch 29/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0226 - val_accuracy: 0.9917\n",
      "Epoch 30/100\n",
      "5278/5278 [==============================] - 0s 71us/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.0236 - val_accuracy: 0.9902\n",
      "Epoch 31/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.0226 - val_accuracy: 0.9909\n",
      "Epoch 32/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.0214 - val_accuracy: 0.9924\n",
      "Epoch 33/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0217 - val_accuracy: 0.9909\n",
      "Epoch 34/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0235 - val_accuracy: 0.9924\n",
      "Epoch 35/100\n",
      "5278/5278 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 74us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9924\n",
      "Epoch 36/100\n",
      "5278/5278 [==============================] - 0s 83us/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.0249 - val_accuracy: 0.9902\n",
      "Epoch 37/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0052 - accuracy: 0.9996 - val_loss: 0.0208 - val_accuracy: 0.9939\n",
      "Epoch 38/100\n",
      "5278/5278 [==============================] - 0s 74us/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0168 - val_accuracy: 0.9932\n",
      "Epoch 39/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0192 - val_accuracy: 0.9932\n",
      "Epoch 40/100\n",
      "5278/5278 [==============================] - 0s 66us/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0202 - val_accuracy: 0.9932\n",
      "Epoch 41/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0214 - val_accuracy: 0.9924\n",
      "Epoch 42/100\n",
      "5278/5278 [==============================] - 1s 104us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9932\n",
      "Epoch 43/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0178 - val_accuracy: 0.9932\n",
      "Epoch 44/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9932\n",
      "Epoch 45/100\n",
      "5278/5278 [==============================] - 0s 66us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9939\n",
      "Epoch 46/100\n",
      "5278/5278 [==============================] - 0s 65us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9939\n",
      "Epoch 47/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0171 - val_accuracy: 0.9947\n",
      "Epoch 48/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9955\n",
      "Epoch 49/100\n",
      "5278/5278 [==============================] - 0s 80us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9939\n",
      "Epoch 50/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9932\n",
      "Epoch 51/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9932\n",
      "Epoch 52/100\n",
      "5278/5278 [==============================] - 0s 76us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9955\n",
      "Epoch 53/100\n",
      "5278/5278 [==============================] - 0s 71us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0216 - val_accuracy: 0.9939\n",
      "Epoch 54/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9939\n",
      "Epoch 55/100\n",
      "5278/5278 [==============================] - 0s 74us/step - loss: 9.6107e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9947\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5278/5278 [==============================] - 0s 85us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9939\n",
      "Epoch 57/100\n",
      "5278/5278 [==============================] - 0s 71us/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0168 - val_accuracy: 0.9947\n",
      "Epoch 58/100\n",
      "5278/5278 [==============================] - 0s 66us/step - loss: 7.5888e-04 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9939\n",
      "Epoch 59/100\n",
      "5278/5278 [==============================] - 0s 67us/step - loss: 7.0670e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9962\n",
      "Epoch 60/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 6.2303e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9939\n",
      "Epoch 61/100\n",
      "5278/5278 [==============================] - 0s 65us/step - loss: 6.4277e-04 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9947\n",
      "Epoch 62/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 6.0216e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9955\n",
      "Epoch 63/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 5.2749e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9955\n",
      "Epoch 64/100\n",
      "5278/5278 [==============================] - 0s 67us/step - loss: 5.0129e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9955\n",
      "Epoch 65/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 5.0951e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9947\n",
      "Epoch 66/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 5.5392e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9955\n",
      "Epoch 67/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0161 - val_accuracy: 0.9947\n",
      "Epoch 68/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0162 - val_accuracy: 0.9947\n",
      "Epoch 69/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 3.8711e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9939\n",
      "Epoch 70/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 3.6951e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
      "Epoch 71/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 3.0336e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9955\n",
      "Epoch 72/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 2.7240e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9947\n",
      "Epoch 73/100\n",
      "5278/5278 [==============================] - 0s 71us/step - loss: 2.5860e-04 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9955\n",
      "Epoch 74/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 2.4647e-04 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9955\n",
      "Epoch 75/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 2.2895e-04 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9955\n",
      "Epoch 76/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 2.2341e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9947\n",
      "Epoch 77/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 2.2749e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9955\n",
      "Epoch 78/100\n",
      "5278/5278 [==============================] - 0s 67us/step - loss: 2.2078e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9962\n",
      "Epoch 79/100\n",
      "5278/5278 [==============================] - 0s 77us/step - loss: 2.2222e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9955\n",
      "Epoch 80/100\n",
      "5278/5278 [==============================] - 0s 76us/step - loss: 2.5096e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9962\n",
      "Epoch 81/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 1.6385e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
      "Epoch 82/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 1.5784e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9955\n",
      "Epoch 83/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 1.5741e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9962\n",
      "Epoch 84/100\n",
      "5278/5278 [==============================] - 0s 72us/step - loss: 1.5807e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9947\n",
      "Epoch 85/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 1.2882e-04 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9955\n",
      "Epoch 86/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 1.7239e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9955\n",
      "Epoch 87/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0153 - val_accuracy: 0.9962\n",
      "Epoch 88/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 1.1466e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9955\n",
      "Epoch 89/100\n",
      "5278/5278 [==============================] - 0s 68us/step - loss: 9.4799e-05 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9955\n",
      "Epoch 90/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 9.0118e-05 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9947\n",
      "Epoch 91/100\n",
      "5278/5278 [==============================] - 0s 64us/step - loss: 8.6777e-05 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9955\n",
      "Epoch 92/100\n",
      "5278/5278 [==============================] - 0s 74us/step - loss: 8.1128e-05 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9962\n",
      "Epoch 93/100\n",
      "5278/5278 [==============================] - 0s 71us/step - loss: 1.2771e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9947\n",
      "Epoch 94/100\n",
      "5278/5278 [==============================] - 0s 67us/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0261 - val_accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "5278/5278 [==============================] - 0s 80us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0159 - val_accuracy: 0.9955\n",
      "Epoch 96/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 2.2123e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9955\n",
      "Epoch 97/100\n",
      "5278/5278 [==============================] - 0s 69us/step - loss: 1.2645e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9955\n",
      "Epoch 98/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 1.0848e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9955\n",
      "Epoch 99/100\n",
      "5278/5278 [==============================] - 0s 70us/step - loss: 9.8415e-05 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9955\n",
      "Epoch 100/100\n",
      "5278/5278 [==============================] - 0s 73us/step - loss: 8.7836e-05 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training  and Testing Accuracy of Deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.9939\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visulization of Training and validation accuracy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visulization of Training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAE/CAYAAABSP5UwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl81NX1//HXISxhJ2ELgmxKlbCIGMEFBXfQsqituNWlVev2tda6oLUutNYN61bbureuyE+LoMUVUbR1YVFBkAAiSljDvi9Jzu+PO4EhZJmEhJlM3s/HYx7MfD738/mcmYTJmTvn3mvujoiIiIiIFK9WvAMQEREREUlkSphFREREREqhhFlEREREpBRKmEVERERESqGEWURERESkFEqYRURERERKoYS5mjKzFDPbaGbtK7NtPJnZgWZW6fMcmtmJZrYw6nG2mR0TS9sKXOspM7uloseLiBRH7/nlOm+1f883sz+Z2T8r+7xScbXjHUBNYWYbox42ALYB+ZHHv3b3F8tzPnfPBxpVdtuawN0PqozzmNklwPnuPiDq3JdUxrlFpHrTe37i0Hu+VAYlzPuIu+9884p8mr3E3d8vqb2Z1Xb3vH0Rm0hZ9PsoUj56zxdJLirJSBCRr19eMbOXzWwDcL6ZHWlmn5nZWjNbamaPmFmdSPvaZuZm1jHy+IXI/rfMbIOZfWpmncrbNrJ/kJnNNbN1Zvaomf3XzC4qIe5YYvy1mc03szVm9kjUsSlm9qCZrTKz74CBpbw+t5rZ6CLbHjOzv0TuX2Jm30aez3eRnoCSzpVjZgMi9xuY2fOR2GYBhxVz3QWR884ysyGR7T2AvwLHRL76XBn12t4Rdfzlkee+ysxeN7M2sbw25XmdC+Mxs/fNbLWZLTOzG6Ou84fIa7LezKaa2X7FfRVqZp8U/pwjr+fkyHVWA7eaWRczmxR5Lisjr1vTqOM7RJ5jbmT/w2aWGom5a1S7Nma22cyal/R8RZKd3vP1nl/ae34xz2FYJJ61ZvaBmR0Ute8WM1sSeY+fE/VcjzCz6ZHty83s/livJ8Vwd9328Q1YCJxYZNufgO3AYMIHmfrA4UBfwjcBnYG5wNWR9rUBBzpGHr8ArASygDrAK8ALFWjbCtgADI3suw7YAVxUwnOJJcZxQFOgI7C68LkDVwOzgHZAc2By+JUs9jqdgY1Aw6hzrwCyIo8HR9oYcDywBegZ2XcisDDqXDnAgMj9UcCHQBrQAZhdpO1ZQJvIz+TcSAytI/suAT4sEucLwB2R+ydHYuwFpAJ/Az6I5bUp5+vcFFgO/AaoBzQB+kT23Qx8DXSJPIdeQDpwYNHXGvik8OcceW55wBVACuH38SfACUDdyO/Jf4FRUc/nm8jr2TDS/ujIvieAu6Ku8ztgbLz/H+qm2766ofd8veeX/z3/T8A/I/e7RuI4PvIzuiXyutcBugE/ABmRtp2AzpH7U4BzIvcbA33j/X+hOt/Uw5xYPnH3N9y9wN23uPsUd//c3fPcfQEh8ehfyvGvuvtUd98BvEj4T1vetj8FvnL3cZF9DxLeaIsVY4x3u/s6d19IeKMqvNZZwIPunuPuq4B7SrnOAkJCNjSy6SRgrbtPjex/w90XePABMBEodpBHEWcBf3L3Ne7+A6EHIfq6Y9x9aeRn8hLhD19WDOcFOA94yt2/cvetwAigv5m1i2pT0muzmzJe5yHAInd/2N23uft6d/8isu8S4BZ3nxd5Dl+5++oY4//R3f/u7vmR38e57j7R3be7+wrC70ZhDEcCLYCb3H1TpP1/I/v+BZxrZhZ5/Avg+RhjEElmes8v+To1+j2/iLOB8e7+QeRndA+hY6QvoWMjFehmoazn+8hrB+GDTxcza+7uG9z98xifhxRDCXNiWRT9wMwONrP/WPiKfT0wkpCUlGRZ1P3NlD7oo6S2+0XH4e5O+HRerBhjjOlahE/JpXkJOCdy/1zCm35hHD81s88tlCSsJXzSL+21KtSmtBjM7CIz+zryNdha4OAYzwvh+e08n7uvB9YAbaPaxPQzK+N13h+YX0IM+wPfxRhvUUV/HzPMbIyZLY7E8M8iMSz0MNhoN5HEOQ/oZ2bdgfbAfyoYk0gy0Xt+6Wrse34Z5y0g/Izauns24Vu7kcAKCyU+GZGmFwOZQLaZfWFmp8b4PKQYSpgTS9HpdR4nfMI+0N2bALcRvn6qSksJX5cBEOkVbFty872KcSkh0SpU1hRIrwAnRj6tDyW8mWJm9YFXgbsJX501A96NMY5lJcVgZp2BvxPKEppHzjsn6rxlTYe0hPCVX+H5GhO+BlwcQ1xFlfY6LwIOKOG4kvZtisTUIGpbRpE2RZ/fvYSR/j0iMVxUJIYOZpZSQhzPAecTepfHuPu2EtqJ1CR6zy9dTX7PL+28tQg/s8UA7v6Cux9NKMdIIbwuuHu2u59NKLt5AHjNzFL3MpYaSwlzYmsMrAM2WRg09et9cM03gd5mNtjMahPqYltWUYxjgGvNrK2FAWA3ldbY3ZcT6myfBbLdfV5kVz1CXW0ukG9mPyXU2sYawy1m1szCnKVXR+1rRHiDzCX8HbmE0NtQaDnQzqIG3xXxMvArM+tpZvUIb2Ifu3uJvTelKO11Hg+0N7OrzayumTUxsz6RfU8BfzKzAyzoZWbphD8aywgDjVLM7DKi3pBLiWETsM7M9geuj9r3KbAK+LOFQTX1zezoqP3PAz8j9BI9V4HnL1IT6D0/Sg1/zy8a8xAzGxC59g2EuvPPzayrmR0Xud6WyC2f8AR+YWYtIj3S6yLPrWAvY6mxlDAntt8BFxL+YzxO+LRdpSJvUMOBvxASoAOALwk9i5Ud498JdWczCYMTXo3hmJcIAzpeiop5LfBbYCxhEMXPCH8EYnE7oddjIfAWUcmcu88AHgG+iLQ5GIiuAXsPmAcsN7Por9kKj3+b8DXZ2Mjx7Qk1bhVR4uvs7usI9X1nEgaczGVXTeH9wOuE13k9od4wNfK166WEwSMrCYMAy6pvux3oQ3jjHQ+8FhVDHqEWsiuht/lHws+hcP9Cws95u7v/r5zPXaSm0Hv+nmrqe370eWcRXvO/E5L5gcCQSD1zPeA+wvv4MkKP9q2RQ08FvrUwC8soYLi7b9/beGoqC383RYoX+Yp9CfAzd/843vFI9WVmzwEL3P2OeMciIsXTe75I8dTDLHsws4Fm1jTyFc8fCAO2vijjMJESRWoDhwLPxDsWEdmd3vNFyqaEWYrTD1hA+IpnIDBMg7SkoszsbsJc0H929x/jHY+I7EHv+SJlUEmGiIiIiEgp1MMsIiIiIlIKJcwiIkkmUpOabWbzzWxEMfsvN7OZZvaVmX1iZplR+26OHJdtZqfs28hFRBJTwpVktGjRwjt27BjvMEREKmTatGkr3b20eWyrVGSWg7mEqQZzCNN3nePus6PaNImsQoaZDQGudPeBkcT5ZcL0gfsB7wM/KW4Fx2h63xaR6irW9+za+yKY8ujYsSNTp06NdxgiIhViZmUt91vV+gDz3X1BJJ7RhBlKdibMhclyREN2rWA2FBgdGfD1vZnNj5zv09IuqPdtEamuYn3PTriEWURE9kpbwuIxhXKAvkUbmdlVwHWEFdOOjzr2syLHFrtMcmR1yMsA2rcva4VjEZHqTTXMIiLJxYrZtkftnbs/5u4HEJYnLlwZLKZjI8c/4e5Z7p7VsmXcKlBERPYJJcwiIsklB9g/6nE7wsptJRkNDKvgsSIiNYJKMkREkssUoIuZdQIWA2cD50Y3MLMu7j4v8vA0oPD+eOAlM/sLYdBfF7Tim0ixduzYQU5ODlu3bo13KBKD1NRU2rVrR506dSp0vBJmEZEk4u55ZnY18A6QAjzj7rPMbCQw1d3HA1eb2YnADmANcGHk2FlmNoYwQDAPuKqsGTJEaqqcnBwaN25Mx44dMSuumkkShbuzatUqcnJy6NSpU4XOoYRZRCTJuPsEYEKRbbdF3f9NKcfeBdxVddGJJIetW7cqWa4mzIzmzZuTm5tb4XOohllERESkApQsVx97+7MqM2E2s2fMbIWZfVPCfjOzRyIrQ80ws95R+y40s3mR24V7FamIiIiIALBq1Sp69epFr169yMjIoG3btjsfb9++PaZzXHzxxWRnZ5fa5rHHHuPFF1+sjJDp168fX331VaWca1+LpSTjn8BfgedK2D+IMDCkC2Guz78Dfc0sHbgdyCJMSzTNzMa7+5q9DVpERESkJmvevPnO5POOO+6gUaNGXH/99bu1cXfcnVq1iu8fffbZZ8u8zlVXXbX3wSaBMhNmd59sZh1LaTIUeM7DGtufmVkzM2sDDADec/fVAGb2HjCQsOyqJIkff4SZM+HEE6FevYqfZ/NmyM4Ot/r14eCDoXNnWLkS5syB77+H/GKGHjVtGtr+5CewZQt8+y3MmwcxfrgGoF8/6Np11+MVK2DCBNixY8+2HTrAgAFQt254vHQpTJwYrl0VDjkE+vTZfVtBAeTkhOe6aBEk2Or25ZKZCUceCYXv5d99B5MnQ15e+c/VsCEMHRr+jbZhw67frc2bYz9f27Zw6qnlj0PKtmwZvPEGDBoE7drFOxqR5DJ//nyGDRtGv379+Pzzz3nzzTe58847mT59Olu2bGH48OHcdlsY0tCvXz/++te/0r17d1q0aMHll1/OW2+9RYMGDRg3bhytWrXi1ltvpUWLFlx77bX069ePfv368cEHH7Bu3TqeffZZjjrqKDZt2sQFF1zA/PnzyczMZN68eTz11FP06tWrxDhfeOEF7r33XtydIUOG8Oc//5m8vDwuvvhivvrqK9ydyy67jGuuuYYHH3yQJ598kjp16tCjRw9eeOGFffVy7lQZg/6KW1WqbSnb96AVoxJLfj6sW1d6m8WL4S9/gRdeCMlN27bwu9/BwIEhYZ0zJyR0c+bA/PnQokVIStu3hx9+CPtycnadb9OmPa9hFnsyWJ62xRk2DC6/HP7zH3jqqdIT4KZNw/P88Uf47LOqT1gHDIAbb4S1a2HsWHj77ZAEJovWreGkk+Drr8OHr73RvDlccw2ccEL40PP66zB7dtnHFefEE5UwV5UFC+Cyy8LvshJmkco3e/Zsnn32Wf7xj38AcM8995Cenk5eXh7HHXccP/vZz8jMzNztmHXr1tG/f3/uuecerrvuOp555hlGjBixx7ndnS+++ILx48czcuRI3n77bR599FEyMjJ47bXX+Prrr+ndu/cex0XLycnh1ltvZerUqTRt2pQTTzyRN998k5YtW7Jy5UpmRv4YrF27FoD77ruPH374gbp16+7ctq9VRsJc0spQ5VoxCngCICsrqxr3l1VfkyfDY4+F5GLePNi2rexj6teHK6+E/v3h0UfhuuvCrVDr1iFJPv10yM0NSfI774SkOTMz9C6lpIS2TZqEtgcfvKuneP58aNUqbD/ggF29utFWrgxts7NDz+LBB8NBB0GDBrE9761b4bnn4JFHQnJVuzb84hch6Sq6eJk7fPVVSFonTIA2beDOO2Hw4D3bVob8fHj1VXjggV2JW0YGnH02HHZYeK6dOu16Daub/Hz47393vZ7du8ODD4YPI40bl/98330H998Pt98ebikpcOyxcO654fftoIPCh51Y7c03JlK61NTwbyzvMyLVwbXXhr8PlalXL3jooYode8ABB3D44YfvfPzyyy/z9NNPk5eXx5IlS5g9e/YeCXP9+vUZNGgQAIcddhgff/xxsec+44wzdrZZuHAhAJ988gk33XQTAIcccgjdunUrNb7PP/+c448/nhYtWgBw7rnnMnnyZG666Says7P5zW9+w6mnnsrJJ58MQLdu3Tj//PMZOnQow4YNK+3UVaYyEuaSVobKIZRlRG//sBKuJxVw//3wxRchySpMTA86KJQu3Hhj6FVt3Tp8/T9oUOgxLm1Aab16cMYZuxLFM84Iva3Z2eG8Bx0EaWkVj7doGUJJ2rYNZQt748474frrQ9J25JEhoS9Ju3bw05/u3fXK47rr4KqrwtfX++0HRxyxq3whGbRvD+ecUznnats2JMgzZoQPUSeeGHqcJfEUfhjReg8iVaNhVG3avHnzePjhh/niiy9o1qwZ559/frGLrdSN6pVKSUkhr4TauHqR/8DRbbycX7WW1L558+bMmDGDt956i0ceeYTXXnuNJ554gnfeeYePPvqIcePG8ac//YlvvvmGlH3cW1QZCXPhJPijCYP+1rn7UjN7B/izmRWmTScDN1fC9aScnnwyJMX77Qf//neogS2UmhpqdW+8MfTKxdozW5wjjgi36qhxYxg+PN5RFK9ePfjZz+IdRfXRs2e4SeIq7GFWwizJoqI9wfvC+vXrady4MU2aNGHp0qW88847DBw4sFKv0a9fP8aMGcMxxxzDzJkzmV1GLdwRRxzBDTfcwKpVq2jatCmjR4/m+uuvJzc3l9TUVH7+85/TqVMnLr/8cvLz88nJyeH444+nX79+vPjii2zevJnGFfkqci+UmTCb2cuEnuIWZpZDmPmiDoC7/4MwOf6pwHxgM3BxZN9qM/sjYZlWgJGFAwClcq1cCU8/HXp0u3YNXz8X9qx9/jlcfTWcckqoz83L21VjPGcOLFkSaglLqcsXEalUKskQ2Xd69+5NZmYm3bt3p3Pnzhx99NGVfo3/+7//44ILLqBnz5707t2b7t2707SUGrh27doxcuRIBgwYgLszePBgTjvtNKZPn86vfvUr3B0z49577yUvL49zzz2XDRs2UFBQwE033bTPk2UAK283elXLysryqVOnxjuMasEdnn8+fG2/atWu7WahtGDIkFBbXLcuTJ0K6enxi1WkpjCzae6eFe849qXyvm+vXBnKuR55BP7v/6owMJEq9O2339I1eoqlGiwvL4+8vDxSU1OZN28eJ598MvPmzaN27cRaULq4n1ms79mJ9UwkJu5hkN6dd8KkSXDUUfCPf4SBc99+G2qVX38dRowIA/P+9z8lyyKSOFSSIZJcNm7cyAknnEBeXh7uzuOPP55wyfLeSq5nk8TWrg0lFLNmwTPPhCS4VSv429/g17/eNRCsQ4cwy8Btt8HChWFQ309+EtfQRUR2o5IMkeTSrFkzpk2bFu8wqlQSjbdPThs3hlkE0tJCmcUll4T5i//615AQX3FFybMmdOyoZHmfWrECRo2q2KobieqHH+BPfworpBRyD19hPPVU8avJQFhp5t57wy9wWdasgbvvLv8kzKtWhWssWVK+4yTuatcO71vqYRaR6kIJcwKbNw/69oUxY8K0Z+PGwdy5YdL/q64K5RaSQG68EW64IXwFUN3l54dh3926wR/+EEaSPvpoSISHDAmTa196afgU9/XXu47LywsfGrp1CzVBv/xlySu7uMMrr4SRqrfcAr17h3/LWjbRPayYc/DB4RrDhinzqoZSU/VjE5HqQyUZCcQ9zGQxdWoov3jrLahTB959N6xcJjH47DP4859D4nrMMaW3dQ8rlBx5ZFjdYm/Mnh1GYNauHYrLf/GLPT/RzJkDN98clkksKi0tHFc4L9+KFSF5bNQobC9rxY2nn4YnntiVnB5zDNxxx64VQCZMgPvuK35t6IMOgnvuCRMZA3z5ZUiGp00LK6aMGAF33RVeq9/8JjyvBx4IK7dce21YReXQQ8No09zc8NXHkCEhyb7nHjj88PDzWL8+zF343/+G62zaFF63rCwYPRr+9a/Q0/yvf+2KZb/9wrbCQRoLFoSvVd59N3yavPnmsMTk1VeH+ROLTh4+alT4xFkRffqEr3KkSqSmqiRDRKoPJcwJ5Pbb4Y9/DH/zO3WCk08Of+87dIh3ZNXA+vUhwfzb30LS+OmnMH067L9/yceMGxcSon/8I7zIJU21475nIlZ02623hqUGn302TJr82GPhawEIWcE994REvkGDkKAX9fXXYfTmlVeGlVhuuimUM+Tnw//7f6F3t3DFlFq1QmJe6L33wtyAmZnh+W7bFpbMGzMmlCyMHx96cg84YM8aHfewnOC4cSEp/vHHcGyLFiGJPeus8Dzfeis8njgxPNeOHcPxp5wCI0eGrz4gLEX4wAOhBxrCco0jRoRe48cfh6VL4fjjw9QtLVqE9civvDIsyzdgQPig8eijuzKpyZPDnIc33xxeuzvuCM/90UdD4pySAqtXh9j79AmvQ6Ht20M5SYsWFatNKs+ygFJu9eqph1lEqhF3T6jbYYcd5jXR3/7mDu4XX+y+ZUu8o6lmxo51b9vW3cz9mmvcp0xxb9zYPSur5BczL889M9O9Sxf3Aw90z8hwX7Jk9zYLFrifeqp7mzbuL7/sXlAQbi+/HLYNGhTafP55+OHdeWc47pRT3NPT3deudf/4Y/euXcP+c85xX7as+HjWrw+xm4W2xxzjPnu2+xdfuB9ySNhWeKtd2/23v3XfsMH9++/dmzd379YtPC706afu3buH9nXruo8c6b51a/HXnj/f/aSTdp3/0kvdV68u14+gROvXh9cZwvP4/PPyHb98ufu55+6K7fTT3Rct2r1NXp77wIHudeq4f/fdru3vvBOOGTdu759HOQBTPQHeS/flrSLv2506uZ9/frkPE0kYs2fPjuv1+/fv72+//fZu2x588EG/4oorSj2uYcOG7u6+ePFiP/PMM0s895QpU0o9z4MPPuibNm3a+XjQoEG+Zs2aWEIv1e233+7333//Xp+nOMX9zGJ9z477G23RW01MmF99NeRJP/2p+44d8Y6mkixdWnlJV7RNm9wnTXKfONH93XdDAgXuPXu6f/bZrnZjx4btv/xlSHKL+te/wv4xY9xnznRv0MD9qKPCeSdOdL/nHvf69d0bNQrnhpCUDRq063qNGoU2Xbq4t2wZkkN392nTdrUB9w4d3CdMiO35TZ3q/sor7vn5u7bt2OH+7LPud90VbhddFM7bvn1IlJs2dZ87d89zbd8ejsvOLvu6BQXu//63+3//G1uc5bFokfvzz4d4KmrixNJfw5wc91q13EeM2LXt8svdGzZ037y54tetACXMsena1f3nPy/3YSIJI94J8z/+8Q+/6KKLdtvWt29fnzx5cqnHFSbMpYklYe7QoYPn5uaWHWg5KWFWwlysSZNCB+CRR4ZcMCkUFLh37uyelub+9NPFJ6wVMWFCSD6je1tTU0NyW1wy9vvfhzYnn7x7z+O2be4dO7r37r0rMX3lld3PC+6DB7v/+GPowXzooZB8NWwY7uflhX2DB4e2Dz+8+7WHDw8J3O9+575xY+U8/2iffBJ6bs3c33ij8s9fHQ0e7N66dfhdyM8P3wKU0HtSlZQwx6ZXr/AjE6mu4p0wr1y50lu0aOFbI98efv/9977//vt7QUGBb9iwwY8//ng/9NBDvXv37v7666/vPK4wYf7++++9W7du7u6+efNmHz58uPfo0cPPOuss79Onz86E+fLLL/fDDjvMMzMz/bbbbnN394cfftjr1Knj3bt39wEDBrj77gn0Aw884N26dfNu3br5gw8+uPN6Bx98sF9yySWemZnpJ510km8upkMjOmH+8ssvvW/fvt6jRw8fNmyYr450xD388MPetWtX79Gjhw8fPtzd3T/88EM/5JBD/JBDDvFevXr5+sJOrCh7kzCrhjmOvv4ahg4NpaVvvBFKNJPC1KlhcNb++8OvfgXPPVf8qMXWreHCC0MxI0BBQajXLayHjfb11/Daa2Hw17//vWvt7wMPDAPDijNyZKipveUW6N491MumpYXzL1wYapcL5+Q76yzo2TMMtoMwWK5Xr111yr/5DZx99q64ITy/cePCdCZduux+7WefDYPs2reP6SUrt6OPDoPzFi0Kv0ASBiq+8Ua47bdfqJcurKWWhKNZMkT2TvPmzenTpw9vv/02Q4cOZfTo0QwfPhwzIzU1lbFjx9KkSRNWrlzJEUccwZAhQ7Ci43Ei/v73v9OgQQNmzJjBjBkz6N279859d911F+np6eTn53PCCScwY8YMrrnmGv7yl78wadIkWrRosdu5pk2bxrPPPsvnn3+Ou9O3b1/69+9PWloa8+bN4+WXX+bJJ5/krLPO4rXXXuP8888v8TlecMEFPProo/Tv35/bbruNO++8k4ceeoh77rmH77//nnr16rF27VoARo0axWOPPcbRRx/Nxo0bSS2c8L2SKGGOk4ULwwIjTZrAO+/syv+SwtixYTDW9Olhvt6bboKPPiq+7UMPhdkdWrQIA7Y+/rj4dqmpYbaIm27alWCXpVatMHvCsGFhhocHH9y179RTw6jKaAcfHG4lKUyUo5kVP6Csfv2qS5YL1a2rZDnaoEFhdo0nnwwffmrXhtNOi3dUUgLNkiFJ5dpr4auvKvecvXqFv5GlOOeccxg9evTOhPmZyLSm7s4tt9zC5MmTqVWrFosXL2b58uVkZGQUe57JkydzzTXXANCzZ0969uy5c9+YMWN44oknyMvLY+nSpcyePXu3/UV98sknnH766TRs2BCAM844g48//pghQ4bQqVMnevXqBcBhhx3GwoULSzzPunXrWLt2Lf379wfgwgsv5Oc///nOGM877zyGDRvGsGHDADj66KO57rrrOO+88zjjjDNo165dqa9deWke5jjYsCH8Hd+6Fd5+u/SJHCrNqFFhRoNTTgmJxTPPlDw/biH3MLvDc8/tvj0nB4YP33W+iy+GHTt27R87Fvr3D0nwJZfAypVhft6it//8J0xzdswxIcH55puwGMaOHXu23bQpLF8Ya7IcrV270Csdfb4339xz5gup3mrXDvM+v/NO+J09/nho1izeUUkJNEuGyN4bNmwYEydOZPr06WzZsmVnz/CLL75Ibm4u06ZN46uvvqJ169ZsLeM/XHG9z99//z2jRo1i4sSJzJgxg9NOO63M83gpuUW9qL/hKSkp5FVwoa///Oc/XHXVVUybNo3DDjuMvLw8RowYwVNPPcWWLVs44ogjmDNnToXOXRL1MO9j7iG/nDMnzAbWrds+uOjs2aFntnPnkMSuWRNKJZ5/Pkz1VdKUW48/HqbzqlUrzLl70knhL9wZZ4Rz9ugRktvCOXEvvzw8sTlzwsoqhcxCj3NRp54akuQ//jGs2nbXXcX34laW4mKQ5PKrX4Wp5JYtC/M0SsJSSYYKyZOLAAAgAElEQVQklTJ6gqtKo0aNGDBgAL/85S8555xzdm5ft24drVq1ok6dOkyaNIkffvih1PMce+yxvPjiixx33HF88803zJgxA4D169fTsGFDmjZtyvLly3nrrbcYMGAAAI0bN2bDhg17lGQce+yxXHTRRYwYMQJ3Z+zYsTz//PPlfm5NmzYlLS2Njz/+mGOOOYbnn3+e/v37U1BQwKJFizjuuOPo168fL730Ehs3bmTVqlX06NGDHj168OmnnzJnzhwOLu1b43JSwryP3XdfKMUdNSp0gO0Tf/hDmCP4009DwlxQEHqYb7gh9OyOH79necKnn4YyhlNOCQttnH12WMjirrtgypTQizxsWPgEcOyxoV74ggvCdgj7YtGoUZgrWKQydOgQfpfffTcMEJCEpZIMkcpxzjnncMYZZzB69Oid28477zwGDx5MVlYWvXr1KjNxvOKKK7j44ovp2bMnvXr1ok+fPgAccsghHHrooXTr1o3OnTtzdNR6BZdddhmDBg2iTZs2TJo0aef23r17c9FFF+08xyWXXMKhhx5aavlFSf71r39x+eWXs3nzZjp37syzzz5Lfn4+559/PuvWrcPd+e1vf0uzZs34wx/+wKRJk0hJSSEzM5NBgwaV+3qlsdK6zuMhKyvLp06dGu8wKt2OHWEc2BVXhHUtRo+uoooA97DaWqtW4fGUKWFBhzvu2LPHbdmykFzk5IRkuFOnXdsPOyz8RZs6NZRUHH54qMtdtgx+//vQi1fo449D0nzvvWERDIAvvqiCJycSg+zs8Ht73nlxubyZTXP3rLhcPE4q8r594YVhaEMF/oaKJIRvv/2WroWrkEq1UNzPLNb3bNUwV7EdO8KibwceCL/+dahcePrpKiyffe65UNZw6aWh9OKWW0Kv8nXX7dk2IyP0CLuHMovNm0Ndcd++sHZt2JeWFmaAeOGFkCwPHBgG30U75phQF13Y+6yZCSSeDjoobsmyxE4lGSJSnShhrkKF5b5XXx3Gnb3xBvz3v6EKYa8VFMCECaE3OdpLL4Up0Z59Nsyg8P77IWlu3Lj48xxwALz4Ypi2rXv3sPxy48ZhCeToUbA//SnMnBkGzxVXC3zXXWF5alDCLCJlUkmGiFQnSpiryMaNYSaMN98MPcyffBJyzkrpWZ4zB447Llzg2mt3bV+7Fj74IAy+mzo1dGv/5CehDqQ0p54aEt6lS0OpxfTpcMQRe7br3j2UZRTn0EPhootC6UYlFtmLSHLSLBkiUp1o0F8V2LAhjJX7/PNQIfGLX1Tiyf/6V/jd78IqJ0cdFUYQPvoopKeHcoq8vNDD26tXqCPOz49tdoibb4brr4c6dSoe29NPV/xYEalRCksy3DXDo1Rf7l7iYiCSWPZ2zJ56mCvZ9u2hDOOLL2DMmEpOlseNg//7vzBQ79tv4W9/C99pFk7XMnZsmP6tb99dx5RnKrW9SZYhTD9XS79SIlK2wkW4oqdwF6lOUlNTWbVq1V4nYlL13J1Vq1bt1ep/6mGuRAUFoSrh/fdDCfGZZ1biybOzQ/adlRWWj05NDYP2+vQJK+Vddhm89VYYeq6kVUQSXOH6BVu3hkUrRaqbdu3akZOTQ27RsUSSkFJTU/dq9T8lzJXoxhvh5ZfD4ngXXVSJJ96wIZRZ1KsXSjCiPyFdemm43XlnmOVCA+5EpBoofBvbuhWaNIlvLCIVUadOHToVTscqSU9dkZXkgw/ggQfCAnc33liJJ54yJUzblp0Nr7wC7dvvvv/ss8O0G/fdF5YBjqzAIyKSyAoTZs2UISLVgRLmSrBlS5hj+cAD4f77YxzAMn9+6I5++eWwisnSpbvv37gxzIBxxBFh6rjXXy9+acBGjeDcc8PImZ/+dO/rkEWk2jOzgWaWbWbzzWxEMfuvM7PZZjbDzCaaWYeofflm9lXkNr6qYowuyRARSXQqyagEf/pTyH/ff7/kWdd24w6DB4fp4Qo1aQJ33x2mhJswAa68MqzAd8UV8Oc/Q9OmJZ/viivCUtfnnrvXz0VEqjczSwEeA04CcoApZjbe3WdHNfsSyHL3zWZ2BXAfMDyyb4u796rqOKNLMkREEp16mPfSN9+EaogLL4QTTojxoI8/DsnyAw+Efz//PAzeu+qqsDz14MEhgf7kkzCJc2nJMoQp5HJzw2p7IlLT9QHmu/sCd98OjAaGRjdw90nuvjny8DOg4iNhKqiwh1klGSJSHShh3gvr1oVO3WbNYNSochz45JMhIf71r8Myvn36wLvvhkmbGzQIi4hMnx7mWY5Vs2bljl9EklJbYFHU45zItpL8Cngr6nGqmU01s8/MbFhVBAjqYRaR6kUlGRW0dSsMHRo6iP/zH2jRIsYDV68O08L96lfQsOGu7WZh2rhKnbhZRGqg4kZRFDtRrJmdD2QB/aM2t3f3JWbWGfjAzGa6+3fFHHsZcBlA+6KDkWOghFlEqhP1MFdAfj6cfz589BH8619w0knlOPiFF8J3kJdeWmXxiUiNlgPsH/W4HbCkaCMzOxH4PTDE3XcWRrj7ksi/C4APgUOLu4i7P+HuWe6e1bJly3IHqZIMEalOlDBXwK23humQH3wQzjmnHAe6h3KMrKxQdywiUvmmAF3MrJOZ1QXOBnab7cLMDgUeJyTLK6K2p5lZvcj9FsDRQPRgwUqjHmYRqU6UMJfTRx/BvfeGDuJrry2l4XffhaX/on3+eRglqN5lEaki7p4HXA28A3wLjHH3WWY20syGRJrdDzQC/l+R6eO6AlPN7GtgEnBPkdk1Ko0SZhGpTlTDXA5r18IFF4T5lh98sJSG06eHXuRLLgnLVgPs2BFWNGnUqJzd0iIi5ePuE4AJRbbdFnX/xBKO+x/Qo2qjC1SSISLViXqYy+Hqq2Hx4lCGHD1ebw+PP76r/OKpp8K2G24I08k9/jg0brxP4hURSVTqYRaR6kQ9zDH64AN48UW4884wC1yJNm6El14Ks10sWxbmVp4/Hx5+ONRwaHERERElzCJSrShhjtHYsWEVvxtvLKPhK6+EpPnyy8Mcy1lZoei5f/+wwomIiKgkQ0SqFZVkxMA9rFZ9wgm7ekVK9MQTkJkJRx4JzZvDuHGh8PmVV6BOnX0Sr4hIoitMmNXDLCLVgRLmGMydCwsWwKmnltFwxgz44oswC4ZF1g7o2TNM1ty6dZXHKSJSXZiFpFkJs4hUBzElzGY20MyyzWy+mY0oZn8HM5toZjPM7EMzaxe17z4zm2Vm35rZI2ZW3CpUCe2tyKKxgwaV0fDJJ6FuXa3WJyISg3r1VJIhItVDmQmzmaUAjwGDgEzgHDPLLNJsFPCcu/cERgJ3R449ijDxfU+gO3A4uy/BWi1MmABdu0LHjqU02rEjjAo888xQiiEiIqVKTVUPs4hUD7H0MPcB5rv7AnffDowGhhZpkwlMjNyfFLXfgVSgLlAPqAMs39ug96VNm8JiJWWWY3z4IaxZA8OH74uwRESqPSXMIlJdxJIwtwUWRT3OiWyL9jVwZuT+6UBjM2vu7p8SEuilkds77v7t3oW8b33wAWzfHkM5xtix0KABnHzyPolLRKS6U0mGiFQXsSTMxdUce5HH1wP9zexLQsnFYiDPzA4kLLXajpBkH29mx+5xAbPLzGyqmU3Nzc0t1xOoahMmhMX5+v1kBfzmN7B+/Z6NCgrg9ddh4MAw95yIiJRJPcwiUl3EkjDnAPtHPW4HLIlu4O5L3P0Mdz8U+H1k2zpCb/Nn7r7R3TcCbwFHFL2Auz/h7lnuntWyZcsKPpXK5x4G/J1wAtR741V45BEYNWrPhl98AUuXwhln7PsgRUSqKSXMIlJdxJIwTwG6mFknM6sLnA2Mj25gZi3MrPBcNwPPRO7/SOh5rm1mdQi9z9WmJGPKFPjhBzjtNGD69LDxL3+BFSt2bzh2LNSuHWkoIiKxUEmGiFQXZSbM7p4HXA28Q0h2x7j7LDMbaWZDIs0GANlmNhdoDdwV2f4q8B0wk1Dn/LW7v1G5T6HqPPZYKMcYPhyYNg0OPjh0h/z5z7sauYeE+fjjoVmzuMUqIlLdqIdZRKqLmJbGdvcJwIQi226Luv8qITkuelw+8Ou9jDEucnNh9OiwBkmTulvhm2/ghhtC7/Lf/w6//S106ACzZ8O8eXDddfEOWUSkWklNhVWr4h2FiEjZYkqYa6KnngqzY1x5JSFZzsuD3r2hb1944QW4+mr42c/g/ffDklVDi860JyIipVFJhohUF0qYi5GXFzqRjz8eMjOBx6eFHYcdBvvvH2bLuO8+ePPNsP2446BNm7jFKyJSHakkQ0SqCyXMxXjjDVi0CB5+OLJh2jRIS9u11N/dd8MVV4T6ZVCyLCJSAUqYRaS6UMJcjMceCx3JgwdHNkyfHsoxLDIlda1aZayTLSIiZVFJhohUF7FMK1ejLFsWVvf75S/DTHFs3w4zZ4ZyDBERqTTqYRaR6kIJcxHjxoVKi51rkMyaFZLm3r3jGpeISLJRwiwi1YUS5iLGjoXOnaFHj8iGaVED/kREpNLUqwf5+WGgtYhIIlPCHGXdulCOcfrpu8qVmTYNmjaFAw6Ia2wiIskmNTX8qzpmEUl0SpijTJgAO3aEhHmn6dPh0EOjMmgREakMhQmzyjJEJNEpYY4ydiy0bg1HHhnZsG4dfP21yjFERKpAvXrhX/Uwi0iiU8IcsXUrvPVWWLCvljn8+9/QtWvocj7ttHiHJyKSdNTDLCLVheZhjsi+8Wne3vgMmZ8Ah24KPcu9esH48ZCVFe/wRESSjhJmEaku1MMc0eylv9HF5tM0owG0bAmjRsEXXyhZFhGpIirJEJHqQj3MgOfl03r1bN458CqGThwV73BERJLb3Llw//007/M74GD1MItIwlMPM7D4o/mk+lYa9u1RdmMREdk769bBU0/RbOV8QCUZIpL4lDADc1+bCUCnIUqYRUSqXHo6AKlbVgMqyRCRxKeEGVj3yUzyqUXn07rGOxQRkeQXSZjrbw4Js3qYRSTR1fiE2R1S581kWeMuWIP68Q5HRCT5NW0KZtTbvAZQwiwiia/GJ8zffQcHbp3J1i4qxxAR2Sdq1YJmzai7USUZIlI91PiE+eO3N3EA39HkKCXMIiL7THo6dTaqJENEqocanzB/98ZsauG0OE4Js4gkBzMbaGbZZjbfzEYUs/86M5ttZjPMbKKZdYjad6GZzYvcLqyyINPTqb1eCbOIVA81OmF2h02fhRkyrKcSZhGp/swsBXgMGARkAueYWWaRZl8CWe7eE3gVuC9ybDpwO9AX6APcbmZpVRJoWhop60MNs0oyRCTR1eiEee5caL9+JjvqNoDOneMdjohIZegDzHf3Be6+HRgNDI1u4O6T3H1z5OFnQLvI/VOA99x9tbuvAd4DBlZJlOnp1FqrHmYRqR5qdMI8aRL0YCb5B3cLg1BERKq/tsCiqMc5kW0l+RXwVgWPrbj0dGz1amrXVsIsIomvRmeJkybBIbVmUu8wlWOISNKwYrZ5sQ3NzgeygPsrcOxlZjbVzKbm5uaWP8r0dFizhtS6BSrJEJGEV2MTZnf45oMVtCxYofplEUkmOcD+UY/bAUuKNjKzE4HfA0PcfVt5jgVw9yfcPcvds1q2bFn+KNPToaCAFvU2qIdZRBJejU2Yv/0WMlaGAX/0UMIsIkljCtDFzDqZWV3gbGB8dAMzOxR4nJAsr4ja9Q5wspmlRQb7nRzZVvnSwljCjLqrlTCLSMKrHe8A4qWwfhlQwiwiScPd88zsakKimwI84+6zzGwkMNXdxxNKMBoB/8/MAH509yHuvtrM/khIugFGuvvqKgk0sjx2q9qr2batU5VcQkSkstTohPnnDWfiDVthrVrFOxwRkUrj7hOACUW23RZ1/8RSjn0GeKbqoouIJMwtU1azVj3MIpLgamRJRkEBfPQRHJ46E1PvsojIvhdJmFvUUkmGiCS+Gpkwz5oFq1YWsP+GWdC9e7zDERGpeSI1zOm2RrNkiEjCq5EJ86RJ0JkF1Nm+WfXLIiLxUJgwox5mEUl8NTJh/vBDOLGVBvyJiMRNaio0aEAaq9XDLCIJr8YlzIX1ywPbzgQz6NYt3iGJiNRM6ek0y1cPs4gkvhqXMM+cCatXw6G1Z0LnztCwYbxDEhGpmdLTaZK/RgmziCS8Gpcwf/ll+LfNypkqxxARiae0NBrnqSRDRBJfjUuY586FRilbqPPDPCXMIiLxlJ5O4x0qyRCRxFfjEubsbDip3bdYQYESZhGReEpPp+E2JcwikvhiSpjNbKCZZZvZfDMbUcz+DmY20cxmmNmHZtYual97M3vXzL41s9lm1rHywi+/uXPh2DTNkCEiEnfp6TTYpnmYRSTxlZkwm1kK8BgwCMgEzjGzzCLNRgHPuXtPYCRwd9S+54D73b0r0AdYURmBV0R+PsybFxnwV68eHHhgvEIREZG0NOrmbcG2bcE93sGIiJQslh7mPsB8d1/g7tuB0cDQIm0ygYmR+5MK90cS69ru/h6Au290982VEnkFLFoE27bBAZtnQmYm1K4dr1BERCSyPHYa6mUWkcQWS8LcFlgU9Tgnsi3a18CZkfunA43NrDnwE2Ctmf3bzL40s/sjPdZxkZ0d/m25XDNkiIjEXSRhTmc1W7bEORYRkVLEkjBbMduKfnl2PdDfzL4E+gOLgTygNnBMZP/hQGfgoj0uYHaZmU01s6m5ubmxR19Oc+dCOquot2qpEmYRkXiL6mFesybOsYiIlCKWhDkH2D/qcTtgSXQDd1/i7me4+6HA7yPb1kWO/TJSzpEHvA70LnoBd3/C3bPcPatly5YVfCply86Gvg2+CQ+6d6+y64iISAyiepirsK9ERGSvxZIwTwG6mFknM6sLnA2Mj25gZi3MrPBcNwPPRB2bZmaFWfDxwOy9D7tisrPhqFbzw4ODDopXGCIiApCWBihhFpHEV2bCHOkZvhp4B/gWGOPus8xspJkNiTQbAGSb2VygNXBX5Nh8QjnGRDObSSjveLLSn0WM5s6FHg0XQEoK7L9/2QeIiEjVUQ+ziFQTMU0T4e4TgAlFtt0Wdf9V4NUSjn0P6LkXMVaKzZvhxx/hgB4LoEMHzZAhIhJvjRvjKSmk5a9h5cp4ByMiUrIas9Lf/EglRpvNC6BTp/gGIyIiYAbp6bSspR5mEUlsNSZhLpxSrsnq76Fz5/gGIyIiAFhaGhn1lDCLSGKrMQnz3LnQiA3UWZOrhFlEJFGkp9OqthJmEUlsNSZhzs6GI1p9Hx4oYRYRSQzp6aSbaphFJLHVmIR57lw4svWC8EA1zCIiiSE9nWYF6mEWkcRWIxJm99DD3LOxephFRBJKejqNdyhhFpHEViMS5lWrYO1aOKDWAmjSZOfcnyIiEmdpaTTYtpZNG/LZti3ewYiIFK9GJMyLFoV/22xeEHqXzeIbkIiIBM2bA2HxEtUxi0iiqlEJc9M136t+WUQkkbRuHf5hucoyRCRh1YiEOScHjAJSl2oOZhGRhNKmDQAZLFPCLCIJq0YkzIsWQbuUZdjWrUqYRUQSSUZG+EcJs4gksBqRMOfkQJ8WkSnllDCLiCSOqIRZNcwikqhqTMJ8SJPIlHKqYRYRSRyNGuENGtBGPcwiksBqRMK8aBF0rbcgzI7RoUO8wxERkUJmWEYGHeopYRaRxJX0CbN76GHuWLAA2raF1NR4hyQiItEyMmibopIMEUlcSZ8wr1oF27ZBm60LVL8sIpKIMjLIYKl6mEUkYSV9wlw4B3P6Ws3BLCI1g5kNNLNsM5tvZiOK2X+smU03szwz+1mRfflm9lXkNn6fBJyRQYs8lWSISOKqHe8AqlpODqSyhfqrF6uHWUSSnpmlAI8BJwE5wBQzG+/us6Oa/QhcBFxfzCm2uHuvKg80WkYGjbevZt2KbUC9fXppEZFY1Ige5mOZHB707h3fYEREql4fYL67L3D37cBoYGh0A3df6O4zgIJ4BLiHyNRytVevID8/zrGIiBQj6RPmnBw408bijRrBiSfGOxwRkarWFlgU9Tgnsi1WqWY21cw+M7NhlRtaCSKr/bXyZaxZs0+uKCJSLkmfMC9eVMCwWuOwQYM0Q4aI1ARWzDYvx/Ht3T0LOBd4yMwOKPYiZpdFEuupuXtbfKzV/kQkwSV9wtx41me0yl8Gw/ZNR4mISJzlAPtHPW4HLIn1YHdfEvl3AfAhcGgJ7Z5w9yx3z2rZsmXFowUlzCKS8JI+Ye71/VjyatWB006LdygiIvvCFKCLmXUys7rA2UBMs12YWZqZ1YvcbwEcDcwu/ahK0KoVoOWxRSRxJXXC7AXOcevG8l3746Fp03iHIyJS5dw9D7gaeAf4Fhjj7rPMbKSZDQEws8PNLAf4OfC4mc2KHN4VmGpmXwOTgHuKzK5RNerWJT+tOW00F7OIJKiknlZu7SffcIB/x8TDb+CgeAcjIrKPuPsEYEKRbbdF3Z9CKNUoetz/gB5VHmAxrE0GGWuWMVsJs4gkoKTuYd768lgKMLacPLTsxiIiEje12oTlsdXDLCKJKKkT5vrvj+dTjqRVz4x4hyIiIqXJyKCNqYZZRBJTcifMi79jOr1pt8cXjyIiklAyMmhVsIzcFeWZAU9EZN9I3oR5xw7qbVnL6lotaN063sGIiEipMjJILdjC5uUb4h2JiMgekjdhXrUKgLymLUhJiXMsIiJSushqf/mLl8U5EBGRPSVvwlxYCLe3E+qLiEjViyxeUmf1MrZsiXMsIiJFJH3CXKdNizgHIiIiZYokzG1Yyg8/xDkWEZEikjZh9tyQMDdor4RZRCThRS2PrYRZRBJN0ibMW34Mk3k27qSEWUQk4aWl4XXqkMEyFi6MdzAiIrtL2oR548LQw5zWRQmziEjCq1ULWrdmP1PCLCKJJ2kT5q05K1lHE9p0qBvvUEREJAaWkUHHVCXMIpJ4kjZh3rFsJStpwX77xTsSERGJSUYGbVM06E9EEk/SJsy2UgmziEi10qEDbbctYOH3Wu1PRBJLTAmzmQ00s2wzm29mI4rZ38HMJprZDDP70MzaFdnfxMwWm9lfKyvwstRem8vaOi2pX39fXVFERPZKjx7U37GBOst+ZOvWeAcjIrJLmQmzmaUAjwGDgEzgHDPLLNJsFPCcu/cERgJ3F9n/R+CjvQ83dvU3rWRrQw34ExGpNrp3B6AHM/nxxzjHIiISJZYe5j7AfHdf4O7bgdHA0CJtMoGJkfuToveb2WFAa+DdvQ83do23rWRHUyXMIiLVRlTCrDpmEUkksSTMbYFFUY9zItuifQ2cGbl/OtDYzJqbWS3gAeCG0i5gZpeZ2VQzm5qbmxtb5KXZvJnUgi3QQgmziEi10bQpeW3b051vNFOGiCSUWBJmK2Zb0REZ1wP9zexLoD+wGMgDrgQmuPsiSuHuT7h7lrtntWzZMoaQSpe/LCTdKa2VMIuIVCe1enanJzOVMItIQqkdQ5scYP+ox+2AJdEN3H0JcAaAmTUCznT3dWZ2JHCMmV0JNALqmtlGd99j4GBlWj13JS2B1P33PvkWEZF9p1bPHhz01nssWrADqBPvcEREgNgS5ilAFzPrROg5Phs4N7qBmbUAVrt7AXAz8AyAu58X1eYiIKuqk2WANfNCwqxlsUVEqpkePajLDnxONtA93tGIiAAxlGS4ex5wNfAO8C0wxt1nmdlIMxsSaTYAyDazuYQBfndVUbwx2fB9WBa76QFKmEVEqpXIwL/GP3wT50BERHaJpYcZd58ATCiy7bao+68Cr5Zxjn8C/yx3hBWwZVFImFt2VcIsIlKtHHwwBZZCuzUz2bbtbOrVi3dAIiJJutJf3tJc8qlFy5+kxTsUEREpj3r1WNfmILozk0WlDhcXEdl3kjJh9pUrWVOrOSl1kvLpiYgktR0H9aA732guZhFJGEmZUdZes5L1dVWOISJSHdU5tDud+Z7FczbEOxQRESBJE+bUjSvZomWxRUSqpcZH9QBgy9RZcY5ERCRIyoS58dZctjfVHMwiItVR7UNDwpwye2acIxERCZIuYd6yBdIKVkJz9TCLiFRLHTuyJaUhDRYoYRaRxJB0CfOSnAKas4paWhZbRKR6qlWLFa170G7V1+zYEe9gRESSMGFeMW8dtcknta0SZhGR6mpbZm96+ZfMmV0Q71BERJIvYV6dnQtAo06qYRYRqa4aHtObJmxgwXvfxTsUEZHkS5jXL9Cy2CIi1V2rQYcBsHHy9DhHIiKShAlz4bLYDTsoYRYRqa7qHJLJdqtLnZnT4h2KiEjyJcw7loaE2VoqYRYRqbbq1mVxeg8ylqiHWUTiL+kS5nobQsJMS9Uwi0jNZGYDzSzbzOab2Yhi9h9rZtPNLM/MflZk34VmNi9yu3DfRb2njV160337dFYs93iGISKSfAlzw825bLNUaNAg3qGIiOxzZpYCPAYMAjKBc8wss0izH4GLgJeKHJsO3A70BfoAt5tZWlXHXJI6fXuTzhrmvvdDvEIQEQGSMWHeupJ1dVuAWbxDERGJhz7AfHdf4O7bgdHA0OgG7r7Q3WcARedsOwV4z91Xu/sa4D1g4L4IujitTw0D/1a9r7IMEYmvpEuYm2zNZUNd1S+LSI3VFlgU9Tgnsq2qj610acf2II8UbLoG/olIfCVdwtxs+3LW128d7zBEROKluK/XYi0CjvlYM7vMzKaa2dTc3NyYgyuX1FR+bNyN9IXqYRaR+Eq6hDltxwo2NFDCLCI1Vg6wf9TjdsCSyj7W3Z9w9yx3z2pZhYOsV3fozU82TGPHdg38E5H4Sa6E2Z3mecvZ1KhVvCMREYmXKUAXM+tkZnWBs4HxMR77DnCymaVFBvudHNkWP71704pc5k+ONecXEal8yZUwb9hAKtvY0lg9zCJSM7l7HnA1IdH9Fhjj7rPMbKSZDQEws8PNLAf4OfC4mc2KHLsa+CMh6Z4CjIxsi5v0k8LAv2UTVJYhIvFTO94BVKrly1llGPEAACAASURBVAHY2kQ9zCJSc7n7BGBCkW23Rd2fQii3KO7YZ4BnqjTAcmg/+BC2UZda778LDI53OCJSQyVXD/OKFQBsa6YeZhGRZFC7aUP+1/p0es1+EbZujXc4IlJDJVXCnL8sJMw70tTDLCKSLBaf/Eua5q9h00vj4h2KiNRQyZUwLw4lGXnN1cMsIpIs2l5wAj/Qns1/TZhKERGpYZIqYc5bGnqYC5pX3RRHIiKyb/U9KoXna11E8y/fgx9/jHc4IlIDJVXC7EuXs4p06jasE+9QRESkkjRoAF8echG1cPjnP+MdjojUQMmVMK9YwQpakZoa70hERKQyHXhSJybaCRQ88ywUFMQ7HBGpYZIqYbYVy1lOayXMIiJJ5thj4Wn/JbV+WAiTJ8c7HBGpYZIqYU5ZqR5mEZFkdPTRMJ6hbK/TAMaMiXc4IlLDJFXCXHu1ephFRJJRs2Zw4CEN+V/6T+HVVyEvL94hiUgNkjwJ8/bt1N6wVj3MIiJJ6phj4Mm1Z0FuLnz0UbzDEZEaJHkS5sgqf+phFhFJTsccA2O3DSK/fkOVZYjIPpV0CbN6mEVEktPJJ0N+3QZ8vf9geO01lWWIyD6TPAnz8rDKn3qYRUSSU7NmcNpp8NcVZ8GqVTBpUrxDEpEaInkSZvUwi4gkvfPOg5fXDiSvfiOVZYjIPpM8CbN6mEVEkt6pp0LdJvWZ0mYI/PvfsHFjvEMSkRogeRLmFSvYUbcBm2ikhFlEJEnVrw9nnAG3LbsKVq+G22+Pd0giUgPElDCb2UAzyzaz+WY2opj9HcxsopnNMLMPzaxdZHsvM/vUzGZF9g2v7Cew0/LlbGrYCkAJs4hIEjv3XHh/81EsOPnX8NBDMHVqvEMSkSRXZsJsZinAY8AgIBM4x8wyizQbBTzn7j2BkcDdke2bgQvcvRswEHjIzJpVVvC7WbGCDQ1aYwZ16lTJFUREJAEcdxy0bg131Lsn3Ln0Us2YISJVKpYe5j7AfHdf4O7bgdHA0CJtMoGJkfuTCve7+1x3nxe5vwRYAf+/vXuPz7H+Hzj++mAzZzOETYZUGGOGyr4IOfR1KB0QNVI6iI7fIn2jdPiG0MGjXyqS/Eh0mH6+VCL1rZxKhELR15wZSk6bvX9/vO9tt9lmZtu9+977+Xhcj933dX2u+/pc17Vde9/v63N9PlTLj4qfZe9e/gzRB/6cK5AtGGOMKQJKlYI+fWDup5X561+vwNq1MGmSr6tljAlguQmYw4EdXu8TPfO8/Qjc4Hl9PVDBORfmXcA51woIBn7NW1XPYd8+Dpe2B/6MMaY4uPVWOHkSZh3vDd27wzPPwB9/+LpaxpgAlZuAOat8rWR6/wjQzjn3A9AO2Amk3x9zztUEZgKDRCT1rA04N8Q5t9o5t3r//v25rny61FQNmIOrU7r0+a9ujDHGv7RoAY0awYx3nD7498cf8Oabvq6WMSZA5SZgTgRqe72PAHZ5FxCRXSLSW0SaA6M8844AOOcqAv8HPCEi32W1ARGZKiKxIhJbrVoeWmwcOgSnT5MUZBlmY4wpDpyD+Hj45hvYUikW2rXTBwCTk31dNWNMAMpNwLwKaOCcq+ucCwb6AgneBZxzVZ1zaZ81EpjmmR8MfIg+EPh+/lU7E08fzAdL2qAlxhhTXAwYACVKwDvvAI88Ajt2wPsF96/GGFN8nTNgFpEU4D5gMbAJmCsiG5xzTzvnenqKtQd+cc5tBi4CnvXMvxloCwx0zq31TM3yeyfSRvnbX8IyzMYYU1zUqgWdOmnAnNr1Wrj8cpgwASRzq0FjjLkwpXJTSEQWAgszzXvS6/U8YF4W670LvHuBdTw3T4bZhsU2xpjiJT5eh8v+8qsSXP3ww9rF3NKl0KGDr6tmjAkggTHSnyfDvEcsw2yMMcXJdddBhQowYwbaRqN6dXjxRV9XyxgTYAIjYK5SBa66in0pVSxgNsaYYqRsWc0wz54N2/eEwD33wMKFsHmzr6tmjAkggREw9+8P//kPx0+WsIDZGGOKmVGj9OG/f/4TuPtuHe71lVd8XS1jTAAJjIDZ48QJLGA2xphiJiICHngAZs2CtXtqQN++8PbbcOSIr6tmjAkQFjAbY4zxe489BqGhMGIEcP/9cPQoTJvm62oZYwKEBczGGGP8XuXK2jRj8WJYcrgFxMVps4y9e2HuXBg7Fo4d83U1jTF+KlfdyvkLC5iNMab4uvdeeOklePxx+O6R+3E33wQ1amQUKFNGBzgxxpjzZBlmY4wxASEkBJ54AlauhEUh18GDD8Izz8C330LHjjqoyfHjvq6mMcYPBUzAnJoKp05ZwGyMMcVZfDxERsLosaWQFydqO40rrtAuNPbuhbfe8nUVjTF+KGAC5pMn9acFzMaY4s4519U594tzbqtzbkQWy0s7597zLF/hnIv0zI90zh13zq31TP9T2HW/UMHBGiOvWqXdMadr21bbNb/wgmZXjDHmPARMwHzihP60gNkYU5w550oCU4BuQCOgn3OuUaZig4FDInIJMAl4wWvZryLSzDPdXSiVzmfx8VC3LowZAyKemc5pe43ERHjnHV9WzxjjhyxgNsaYwNIK2Coiv4nIKWAO0CtTmV7ADM/reUBH55wrxDoWqKAgjY1Xr4aPP/Za0LkzxMZqjxk//+yz+hlj/I8FzMYYE1jCgR1e7xM987IsIyIpwBEgzLOsrnPuB+fcl865vxV0ZQvKrbdCw4b63F96b3LOweTJ2kdzs2b6EODp0z6tpzHGP1jAbIwxgSWrTLHkssxu4GIRaQ48BPyvc65ilhtxbohzbrVzbvX+/fsvqMIFISgIXnsNtm/XjjLStWkDGzZA167wj39At24Z/0CMMSYbFjAbY0xgSQRqe72PAHZlV8Y5VwqoBCSJyEkROQggImuAX4FLs9qIiEwVkVgRia1WrVo+70L+aNdO2zNPmAAbN3otqFEDPvwQpk6Fzz6D/v0t02yMyZEFzMYYE1hWAQ2cc3Wdc8FAXyAhU5kEIN7z+kbgCxER51w1z0ODOOfqAQ2A3wqp3gVi/HgoX14HNRHvPLtzcOed2kTjgw9g6NBMBYwxJoMFzMYYE0A8bZLvAxYDm4C5IrLBOfe0c66np9hbQJhzbiva9CKt67m2wDrn3I/ow4B3i0hS4e5B/qpWDcaNgy+/hGefzaLA/ffDiBHw+uvwr38Vev2MMf4hYIbGtoDZGGOUiCwEFmaa96TX6xPATVmsNx+YX+AVLGSDB8Py5Tp2Sf360K9fpgLPPQfbtmmBTp2gZUuf1NMYU3RZhtkYY0xAcw7eeEPHLhk4EP7znywKvPYa1KwJAwZ4dathjDHKAmZjjDEBr3Rpbapcpw707AkrV2YqEBoKM2bA5s3w6KM+qaMxpuiygNkYY0yxEBYGixZBpUrQoQMsXpypQIcO2nHzlCnw97/DyJEwZw7s3u2T+hpjig5rw2yMMabYqFcPvvlGu1/u3h3eflt7lUv33HNw8iR89RV8+imkpOj8xo3hlls0iA6cQRGNMblkGWZjjDHFSo0a2mvG3/6mIwJOm+a1MCREM8zr1sFff+n42uPGQZUqMGoU/PvfPqu3McZ3LGA2xhhT7FSsCP/3f9Cli/ai8T//k0Wh4GBo0UJHBFyyBBo00NdpWWdjTLERcAFzcLBv62GMMcY/lCmjA/517w733KOJ5WwFBWk/zRs3wvTphVZHY0zREFABc0iINS0zxhiTeyEhMH++9pxx333aUUa2rr8e2rSBJ5+Eo0d1ng2pbUyxEHABszHGGHM+goPhvfd0zJLbb9cAOkvO6Vjbe/Zo4ago/cdzzTWwc2dGudRU61nDmABjAbMxxphiLyQEPvoIrrhCRwKcMQNEsih45ZUwZAjs2gWRkXD33fDtt9C0Kbz7LrzwAlx6KdSqBZMnF/ZuGGMKSEB1K2cBszHGmLwqV04fBOzVS0cEXLhQBwCsUiVTwddfP/P9sGHa5dytt+r7du30AcEHH4TDh2H0aGsvaIyfswyzMcYY41G5MnzxBTz/vI4M2LQpfP31OVa69FLt3Pm992DTJli2DBYsgEGD4Kmn9InCgwcLo/rGmAISUBnm0qV9XQtjLlxycjKJiYmcSOv6xRRJISEhREREEBQU5OuqmHxWsiSMGKFNk/v2hfbttSvmBx/MIVEcHAw335zxvlQpePNNHV5wwgRtrnHXXfpkYd26hbEbxph8FFABs2WYTSBITEykQoUKREZG4uw2bpEkIhw8eJDExETqWvATsFq00HFLBg6Ehx+G//wH3ngjiyYa2SlRQh8SHDhQu6R76SWYOBEuu0w7gL7hBh09xf7OjSnyrEmGMUXMiRMnCAsLs2C5CHPOERYWZncBioFKlbRpxvjxkJCgHWMsXnyeH9K4McycCVu3wqRJmmF+4w1t63zJJdrGecoUXTZ1qo4waExxcfiwfqE8edLXNcmRBczGFEEWLBd9do6KD+fgkUdg5UoIDYWuXeGhh/LQBXNkJDzwgA6vvX8/vPMO1KkDTz+tTTUeekibbTRqpF12ZNlNRz5avhyeeQZOnSrY7RiTk9deg5Ej4eOPfV2THFnAbIw5w8GDB2nWrBnNmjWjRo0ahIeHp78/lct/rIMGDeKXX37JscyUKVOYNWtWflTZmELRvDmsWaOx7aRJ2jFGnpNi5cpprxpffAFJSbBvHxw6pA8MVqyog6S0b6/d1K1YAcnJGeuKwM8/64iDP/547sA6NRU++0wfRFyzBr77Dv7+d81w//Of+m3AGF8Q0bsvoLdyijBrw2yMOUNYWBhr164FYMyYMZQvX55HMv1DFRFEhBIlsv7OPT0XQwcPHTr0witrTCELCYFXXtHE8D/+oZ1fzJ+vTTfyLDQ043W7dvD997qRN97Qpw9BHyK85BKdNmyAbdsy1qldW/vCu+UW7Uja++7H0qXw6KPaGNtb5cr6JON//6vbatUKBgy4gJ0wJg/WrtWeZapW1T4di3AwZxlmY0yubN26laioKO6++25iYmLYvXs3Q4YMITY2lsaNG/P000+nl42Li2Pt2rWkpKRQuXJlRowYQXR0NFdeeSX79u0D4IknnmCyZ2CHuLg4RowYQatWrbjsssv45ptvAPjrr7+44YYbiI6Opl+/fsTGxqYH895Gjx5Ny5Yt0+snnozb5s2b6dChA9HR0cTExLB9+3YAnnvuOZo0aUJ0dDSjRo0qyMNmAtQjj+jgJsuWQUQE3HGHPhSYL60ogoK0ecamTTqq4HvvaXTesKEGylFReht73Tp46y2IidEeOa66Svt/jo+Hbt207XSHDrB3r2ajV6zQph4zZsBvv+lnTpwIbdvqYCw//njuuiUna2PuKVN83+Z0zBh49lltA3uhkpO1/8CCbgbjD5KS4PHHYceOgt/Wu+/q7/tLL+lw8599VvDbzKu0TFFRmVq0aCF5Ub26yF135WlVY4qUjRs3pr++/36Rdu3yd7r//tzXZfTo0TJ+/HgREdmyZYs452TlypXpyw8ePCgiIsnJyRIXFycbNmwQEZE2bdrIDz/8IMnJyQLIwoULRUTkwQcflOeff15EREaNGiWTJk1KL//oo4+KiMjHH38sXbp0ERGR559/Xu69914REVm7dq2UKFFCfvjhh7PqmVaP1NRU6du3b/r2YmJiJCEhQUREjh8/Ln/99ZckJCRIXFycHDt27Ix188L7XKUBVksRuJYW5pTX63YgWLVK5PbbRcqVEwH9G1u1ygcVOXJE5O23RTp2FAkPF2nRQqRHD5EXXxQ5fjzndXfvFqlVS6RePZEDB85enpws8uWXIg88IFKtmu4oiLRpI7JvX8Hsz7ksXJhRj4oVRZ54Qo9BXo0YoZ81dWr+1bEgnTwpMmuWyJtviqSm5u9nx8frsahRQ2TFirx9xvvvi7RvL7J6dfZlUlJ0G7166f5UqiQycGDetncBcnvNzlWG2TnX1Tn3i3Nuq3NuRBbL6zjnljjn1jnnljnnIryWxTvntnim+HyL9DOxDLMxBa9+/fq0bNky/f3s2bOJiYkhJiaGTZs2sXHjxrPWKVOmDN26dQOgRYsW6VnezHr37n1Wma+//pq+ffsCEB0dTePGjbNcd8mSJbRq1Yro6Gi+/PJLNmzYwKFDhzhw4AA9evQAtN/ksmXL8vnnn3P77bdTpkwZAKrkuo8wY84WG6tJ3j17tGXDxo3QsqW2jsi3jHNuVKyomeXPP4fERG2CkZCgmepz/XOsUUPblSQmQp8+kJKi8w8e1NR59eraVGTKFM1GJyTA//6vtodu1Up/FmZm9tQp7RS7QQPNml9zjT682LgxLFqkZY4d07axEybo65xs3aqZ9lKlNOu+a9fZZUQ0U5+aeub8Xbu0C5VDh/Jn377+WntK+fJL/aU6dkwz+SdO6F2BZct0XyMjoX9/PT9PPJH98T95EpYs0f2Kj4dsrr/pli3TOxDx8VCmjJ73557T0SxbtIDrrjuzPX1Wdu7Uei1bpk2Enn4663W++EL3ccAA7ce8Z0/93TrX5/vKuSJqoCTwK1APCAZ+BBplKvM+EO953QGY6XldBfjN8zPU8zo0p+3lNVMRHCzy2GN5WtWYIiWrrKWvZM4wR0dHpy/bvHmzNGjQQA4dOiQiIv3795eZM2eKyJkZ5kqVKqWvM3v2bBk8eLCInJ1hTssc7969W+rXry8iItdee60sX748ff0mTZqclWH+66+/pHr16pKYmJj+uWPHjpWkpCSpU6fOWfs0bNgwmT59ep6PiTfLMFuGObMjR0Qefzwj43zJJSL/+peI54ZG0TZ9ulZ6+HCRr74SiYgQCQrSjOO8eWdncFeuFKlZU9eJjBS54w6RmTNFtmzJyHomJ4skJZ1/FnT/fpEFC3RavFhk/fqMZRMn6jY/+SRj3nffiTRqpPM7dNCsc1oG+tJLta7Z6dlTT9iXX4qEhIhcd53W9/hxkfHjNVMaGppxCyHtOBw4kLHN8HCRTz89v33MbNo0kRIlMuqd09Sli2bZ77xT348ceeYxPnxYZNQokfLldXlwsEjZsprFfe+9rLd/4oQeq3r19Bd23z6RuDhdv1w5kauu0tcPPJD9PqSmivz97yJlyuitlv79dZ1WrUR+/fXMsrfdpvVJuwPy4Yda9vPPz++4nT4tkpiY51s7ub1m5+ahv1bAVhH5DcA5NwfoBXinkhoBD3peLwU+8rzuAnwmIkmedT8DugKzzyeoPxcR/cJpGWZjCs8ff/xBhQoVqFixIrt372bx4sV07do1X7cRFxfH3Llz+dvf/sb69euzzGAfP36cEiVKULVqVf7880/mz59P//79CQ0NpWrVqixYsIAePXpw4sQJUlNT6dy5My+88AJ9+vShTJkyJCUlWZbZ5JuKFbVZ7ciRmrSdMUOf25s6FV5+WTunKLIGDtR2zJMnw6uvan/R336rmcWstGypD23Nm6eZ7fff17bUkDG6S1KS/gwN1QxweLhmFRMTNYPZoQN07KgHbscOzaJ++qluN3PWtEMHzXQ+9ZT27XfttRnLWrfWhyXHjoVp0zRbeccdmi0fOBCuvFIzmY0aQf36uk+RkbqthAQdC71tW82GPvqoZmQ/+EDbjMfG6iiOVatqryWdOum+3nwz/Pqrtid/6SXo3Fmzvh076jq1amm2NDlZnwqtUEHr+sMP+suxfr2uc8MNegyHD9f3r7yimeDNm7VP7rT+C2vWhIsv1qHYa9fWeV266EOezz8PX32lWfeKFTW7npSkdbz1Vu1xZf9+vfXRp4/WNzhYg6fwcGjTRvdl82bN0pcpo9PSpVqXyEjNwD/wgP5+tGoF/fqd/Tsxa5Y+vDdpkh6Dd9/Vc3HXXdCsGbz+ura5/+AD3edbbskI3jp3hrJldVnHjmd+bmqqHrdPPtGM+dGjOu/ECfj9d/1ZpowerwLq8jM3AXM44N3yOxFonanMj8ANwEvA9UAF51xYNuuG57m22Uh77sACZmMKT0xMDI0aNSIqKop69erRpk2bfN/GsGHDuO2222jatCkxMTFERUVRKVN3BGFhYcTHxxMVFUWdOnVo3Trj8jRr1izuuusuRo0aRXBwMPPnz6d79+78+OOPxMbGEhQURI8ePRg7dmy+190Ub+XL613t+Hi98zx0KHTvrne4b7kFevfW+KvIGT9eu7grXVoDo4oVcy5fvTrce69Op09rm5Rvv9UmIUFBurxcOW32sGGDNt+oWVMDroMHtSeQl18+8zNbtIAnn9TANCREg7pvv9XmFddfr4HbxIlnB0alS2tzhWeeOXP++vXaNCUhQb/BpKlTRz+7fn1t4gH687334MUX9eHKzz8/M3hr3RpuukkD09RUDe569tQTPWqU7k923WWWLavTgQM6/nrt2trV3/Dh+uXg+uth9mzdj0sv1QDyXEqU0IC9Zk0NdBcv1qYjnTppEN28eUbZ8uW17+1nn9Vyqal6fFes0C8AoMF0ly4Z66T1zpJm/Hj9YjJ4MOzerQFqUpIGrKdOwYcf6sOnw4ZlrHPzzXrcbrlFJ+9j+dhjZx6fbt20jdPSpXocUlL0oc6kJG2e4px+UYuI0H0PDoYePaBePZ1SU/XYFgAn52h35Jy7CegiInd43t8KtBKRYV5lagGvAnWB5Wjw3BgYApQWkWc85f4JHBORFzNtY4inLBdffHGL33///bx24vBh/fI6aZJ++THGn23atImGDRv6uhpFQkpKCikpKYSEhLBlyxY6d+7Mli1bKFWqaPSImdW5cs6tEZFYH1XJJ2JjY2V15m7LzBlOndLE4euvw5Yt+j+9e3cNpDt1KsajY588mdHPdESEBpFly2Zd9vhxePttzdZ6B17n48gRDd6/+07b2K5ZowGnd5C4Y4cG6L17a8CY2dKlGjA+9ZRmb72lpuoJXr1ag7ygIP2Mw4c1s37okGZze/bUb0wbNmiwmpysn5cf1zaR8/+FSkzUQLh9+3N/SdqzR7/wpPWiUb68ZneDg+GiizTov/TSs9dLSdFbLadP65eDiIizy/zwg34ZSgvAS5bULhArVdIM9bXXQrVq57dv55Dba3ZuAuYrgTEi0sXzfiSAiDyfTfnywM8iEuGc6we0F5G7PMteB5aJSLZNMvJy4d2zR79cvfYa3H33ea1qTJFjAXOGw4cP07FjR1JSUhARJkyYQOfcZF0KiQXMygLm3BPRVg9z5mjLgf37M5KJLVtqy4EGDXxdS2PO4cQJDf7DwjRQ9mO5vWbn5qvMKqCBc64usBPoC5zx1c45VxVIEpFUYCQwzbNoMfCccy6tV/bOnuX56sQJ/WlNMowJLJUrV2bNmjW+roYx+cY5TZQ1a6YJxfff1y6Sp0/XZsOggfPgwdC37wUOiGJMQQkJ0UxlMXLObuVEJAW4Dw1+NwFzRWSDc+5p51xPT7H2wC/Ouc3ARcCznnWTgLFo0L0KeDrtAcD8ZAGzMcYYf1O6tD6HtmSJthRYv17vRh8/rndLL7pI79zPmKHPnvl6nBBjirNcNZYRkYXAwkzznvR6PQ+Yl82608jIOBcIC5iNMcb4s5Il9RmzqCh9Fmf1au3qeP58fS4sTdWq2sx00CBtxlFEmvMbE/AC4k/NAmZjjDGBIq0jgJYtNeO8Zo2Ogr1rl2aaExK0R66aNbWDgG7dtMe1cz2rZYzJOwuYjTHGmCLKOe3ONtbrkaRTp7Q72lmztEOCqVN1fu3a+gBhZKT2HBUaqt0Od+yY0QWwMSZvcjU0dlFnAbMx+ad9+/YsXrz4jHmTJ0/m3nvvzXG98uXLA7Br1y5uvPHGbD/7XL0pTJ48mWNeQ9lee+21HD58ODdVN6ZYCA7WHs/mz9cufZct0/E22rWDP/+EhQv1AcJRo7T3rrAw7bpu1Ch45x3txe3337UL3cIc0doYf2YZZmPMGfr168ecOXPo4tUv6Zw5cxg/fnyu1q9Vqxbz5mX5SEOuTJ48mQEDBlDW0xfrwoULz7GGMcVXcLAGyu3anb3s2DFYuVID6EWLYNw47QrXW0iIji1SvboO+HbJJdqtXVSUjnmRXZfIxhQ3lmE2xpzhxhtv5JNPPuGk55H87du3s2vXLuLi4jh69CgdO3YkJiaGJk2a8PHHH5+1/vbt24mKigJ02Oq+ffvStGlT+vTpw/Hjx9PL3XPPPcTGxtK4cWNGjx4NwMsvv8yuXbu4+uqrufrqqwGIjIzkwIEDAEycOJGoqCiioqKYPHly+vYaNmzInXfeSePGjencufMZ20mzYMECWrduTfPmzenUqRN79+4F4OjRowwaNIgmTZrQtGlT5s+fD8CiRYuIiYkhOjqajpmHaTXGD5Qtqw8IjhunbaCPHYOff9aHCN96S0d5vu8+uPpqHQti61aYMkV76IiL0zbRzZrp4G+PPKID8i1cqKMnHzqkvXosWAAffaRjdaSN4GxMILIMszFF2QMPwNq1+fuZzZrpkLfZCAsLo1WrVixatIhevXoxZ84c+vTpg3OOkJAQPvzwQypWrMiBAwe44oor6NmzJy6bUaVee+01ypYty7p161i3bh0xMTHpy5599lmqVKnC6dOn6dixI+vWrWP48OFMnDiRpUuXUjXTuMFr1qxh+vTprFixAhGhdevWtGvXjtDQULZs2cLs2bN54403uPnmm5k/fz4DBgw4Y/24uDi+++47nHO8+eabjBs3jhdffJGxY8dSqVIl1q9fD8ChQ4fYv38/d955J8uXL6du3bokJeV7b5gFyjnXFXgJKAm8KSL/yrS8NPAO0AI4CPQRke2eZSOBwcBpYLiInNk+x/itoCC47DKdspOaCjt36mVn5UpYtUpfJyRk/K/NTkiINv8oWVK3FR6u2erISA2mjx/XDHeFChqMR0RATIyOaJyXkQ6PHtVtFsWeQo4d02PpaalmcrBtm7bDv/VWbXNfVBXBX7PzZwGzMfkrrVlGWsA8bZr2DCkiPP744yxfvpwSJUqwc+dO9u7dS40aLi5ivAAADBhJREFUNbL8nOXLlzN8+HAAmjZtStOmTdOXzZ07l6lTp5KSksLu3bvZuHHjGcsz+/rrr7n++uspV64cAL179+arr76iZ8+e1K1bl2bNmgHQokULtm/fftb6iYmJ9OnTh927d3Pq1Cnq1q0LwOeff86cOXPSy4WGhrJgwQLatm2bXqZKlSq5PXQ+55wrCUwBrgESgVXOuQQR2ehVbDBwSEQucc71BV4A+jjnGqGDUzUGagGfO+cuFRHLHRYTJUrow4O1a2sPHGlEYN8++PVXzSYfOKBlIiN1+YYNOh06pMHxqVPw3/9qBnrfPi1TurQG016PKAA68nGdOhpEV6qk/8uDgzXo9g6kS5bU4HjvXh0tcds2KFdOR0eMi4PGjTX4rl07I0A/fFjba//+u26/dWto0qTgguw//4SXXoIJE3Q/O3TQduRdu+o+BoLkZG03HxamzXYuZFj3JUvg5pt1FPFx47Rf8n/+U5sGFTUWMBtTlOWQCS5I1113HQ899BDff/89x48fT88Mz5o1i/3797NmzRqCgoKIjIzkxDnSTllln7dt28aECRNYtWoVoaGhDBw48JyfIzk8nVS6dOn01yVLlsyyScawYcN46KGH6NmzJ8uWLWPMmDHpn5u5jlnN8yOtgK0i8huAc24O0AvwDph7AWM8r+cBrzrd4V7AHBE5CWxzzm31fN63hVR3U0Q5pwOpXHQRXHXV2ctbtcp+3ZMnNUAtWVLfp6RoYLltm3aZ9/332mXekSOQmKjlk5M16E4jokFwSooG2LGx2hf13r3w1Vc6amJuH2AsU0bbbJcqpVNwcMYkoplh0PqmZcvTAvhSpfRLRYkSGdsT0XqdPq0PVB44AL16aXb9o4+0iQtA3brQtq1+KUj7jKCgjM8tWTJjvnNnT5nnn+t8pdUtNTVjn4KD9YtDqVIZZbL7LO+6pB371ath7lzdR9AvKbfdpvvmXb/M9fB+nZqqn7VxI4wdC5dfrk193n9fmwS984729tKhg7alDwnRKe34eG/D+3iUKnXml7z8ZgGzMeYs5cuXp3379tx+++3069cvff6RI0eoXr06QUFBLF26lN9//z3Hz2nbti2zZs3i6quv5qeffmLdunUA/PHHH5QrV45KlSqxd+9e/v3vf9O+fXsAKlSowJ9//nlWk4y2bdsycOBARowYgYjw4YcfMnPmzFzv05EjRwgPDwdgxowZ6fM7d+7Mq6++mt4m+tChQ1x55ZUMHTqUbdu2pTfJ8KMscziww+t9ItA6uzIikuKcOwKEeeZ/l2nd8IKrqikOvL7PAhrYpHV759VK64L8+Sf89ptmwHfu1CA0JESz1hdfrNndo0c1oF25UjOaKSkamCcna5B+6lRGQAYZQWJysmaLT57MCD5Pnz4zcEsLvuPiYOTIjC8Q48bBpk2aSf3iC3348sSJjM9J276/9FYSEqKjT95yC+zZA2+/DY89lvfPu/56HcmyQgXN/j/4IMyZA0uXwrvv6jk7n7plkSvJNwERMA8aBNdcc/YfpTEm7/r160fv3r3PaK7Qv39/evToQWxsLM2aNePyyy/P8TPuueceBg0aRNOmTWnWrBmtPP9FoqOjad68OY0bN6ZevXq0adMmfZ0hQ4bQrVs3atasydKlS9Pnx8TEMHDgwPTPuOOOO2jevHmWzS+yMmbMGG666SbCw8O54oor2LZtGwBPPPEEQ4cOJSoqipIlSzJ69Gh69+7N1KlT6d27N6mpqVSvXp3PPvssV9spArLKF2X+d5xdmdysqx/g3BBgCMDFF198PvUzJt9VqADR0Tplp1o1zYT27Vt49XJO2+U2agTDhmVfzjsQT03VADqrKW1ZGpGzM8SZg++0zKyIfik4eTKjt5TsAvW07Z0+rT/TMuDVqmkzmDR33QU7dujdAe/sfObP9s7Gp2XuQ0Kgfv0z6x8eDg8/rFNKChw8qPU9cSKjLmnbyHxsCvqmoMvpNqcvxMbGyrn6aTUmkG3atImGDRv6uhomF7I6V865NSISm80qBc45dyUwRkS6eN6PBBCR573KLPaU+dY5VwrYA1QDRniX9S6X0zbtum2M8Ve5vWYHRLdyxhhj0q0CGjjn6jrngtGH+BIylUkA4j2vbwS+EM2eJAB9nXOlnXN1gQbAykKqtzHGFFkB0STDGGOM8rRJvg9YjHYrN01ENjjnngZWi0gC8BYw0/NQXxIaVOMpNxd9QDAFGGo9ZBhjjAXMxhgTcERkIbAw07wnvV6fAG7KZt1ngWcLtILGGONnrEmGMUVQUXu2wJzNzpExxhQfFjAbU8SEhIRw8OBBC8iKMBHh4MGDhFhflsYYUyxYkwxjipiIiAgSExPZv3+/r6tichASEkJERISvq2GMMaYQWMBsTBETFBSUPiSzMcYYY3zPmmQYY4wxxhiTAwuYjTHGGGOMyYEFzMYYY4wxxuSgyA2N7ZzbD/yey+JVgQMFWB1fs/3zb7Z//i2v+1dHRKrld2WKMrtun8H2z38F8r6B7V92cnXNLnIB8/lwzq3Ozfjf/sr2z7/Z/vm3QN8/Xwn042r7578Ced/A9u9CWZMMY4wxxhhjcmABszHGGGOMMTnw94B5qq8rUMBs//yb7Z9/C/T985VAP662f/4rkPcNbP8uiF+3YTbGGGOMMaag+XuG2RhjjDHGmALltwGzc66rc+4X59xW59wIX9fnQjnnajvnljrnNjnnNjjn7vfMr+Kc+8w5t8XzM9TXdc0r51xJ59wPzrlPPO/rOudWePbtPedcsK/reCGcc5Wdc/Occz97zuOVgXL+nHMPen4vf3LOzXbOhfj7+XPOTXPO7XPO/eQ1L8vz5dTLnuvNOudcjO9q7p/smu2fAvm6HcjXbAi867avr9l+GTA750oCU4BuQCOgn3OukW9rdcFSgIdFpCFwBTDUs08jgCUi0gBY4nnvr+4HNnm9fwGY5Nm3Q8Bgn9Qq/7wELBKRy4FodF/9/vw558KB4UCsiEQBJYG++P/5exvommleduerG9DAMw0BXiukOgYEu2b7tUC+bgfkNRsC9rr9Nr68ZouI303AlcBir/cjgZG+rlc+7+PHwDXAL0BNz7yawC++rlse9yfC88vcAfgEcGgH46WyOqf+NgEVgW14ngvwmu/35w8IB3YAVYBSnvPXJRDOHxAJ/HSu8wW8DvTLqpxNuTrOds32wymQr9uBfM321D0gr9u+vGb7ZYaZjF+ENImeeQHBORcJNAdWABeJyG4Az8/qvqvZBZkMPAqket6HAYdFJMXz3t/PYT1gPzDdc/vyTedcOQLg/InITmAC8F9gN3AEWENgnb802Z2vgL7mFIKAPn4Bes2GwL5uB+w1G4rVdbvQrtn+GjC7LOYFRHcfzrnywHzgARH5w9f1yQ/Oue7APhFZ4z07i6L+fA5LATHAayLSHPgLP72Vl5mnTVgvoC5QCyiH3u7KzJ/P37kE2u9rYQvY4xeI12woFtftgL1mg123KYDfVX8NmBOB2l7vI4BdPqpLvnHOBaEX3lki8oFn9l7nXE3P8prAPl/V7wK0AXo657YDc9Dbe5OBys65Up4y/n4OE4FEEVnheT8PvRgHwvnrBGwTkf0ikgx8AFxFYJ2/NNmdr4C85hSigDx+AXzNhsC/bgfyNRuKz3W70K7Z/howrwIaeJ72DEYbsif4uE4XxDnngLeATSIy0WtRAhDveR2PtpPzKyIyUkQiRCQSPVdfiEh/YClwo6eYX+5bGhHZA+xwzl3mmdUR2EgAnD/0lt4Vzrmynt/TtH0LmPPnJbvzlQDc5nny+grgSNptQJMrds32M4F+3Q7wazYUn+t24V2zfd2A+wIafl8LbAZ+BUb5uj75sD9x6O2CdcBaz3Qt2mZsCbDF87OKr+t6gfvZHvjE87oesBLYCrwPlPZ1/S5w35oBqz3n8CMgNFDOH/AU8DPwEzATKO3v5w+YjbbtS0azEYOzO1/o7b0pnuvNevTJc5/vgz9Nds323ylQr9uBfM327F9AXbd9fc22kf6MMcYYY4zJgb82yTDGGGOMMaZQWMBsjDHGGGNMDixgNsYYY4wxJgcWMBtjjDHGGJMDC5iNMcYYY4zJgQXMxhhjjDHG5MACZmOMMcYYY3JgAbMxxhhjjDE5+H/IJqgVLLaWhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix: [[564   2]\n",
      " [ 16  78]]\n",
      "F1_ score : 0.896551724137931\n",
      "Accuracy score: 0.9727272727272728\n",
      "precision_score: 0.975\n",
      "recall_score: 0.8297872340425532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train , y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"confusion_matrix:\",confusion_matrix(y_test , y_pred))\n",
    "print(\"F1_ score :\",metrics.f1_score(y_test , y_pred))\n",
    "print(\"Accuracy score:\",metrics.accuracy_score(y_test , y_pred))\n",
    "print(\"precision_score:\",metrics.precision_score(y_test , y_pred))\n",
    "print(\"recall_score:\",metrics.recall_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix: [[484  82]\n",
      " [ 22  72]]\n",
      "F1_ score : 0.5806451612903226\n",
      "Accuracy score: 0.8424242424242424\n",
      "precision_score: 0.4675324675324675\n",
      "recall_score: 0.7659574468085106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_nb = classifier.predict(X_test)\n",
    "print(\"confusion_matrix:\",confusion_matrix(y_test , y_nb))\n",
    "print(\"F1_ score :\",metrics.f1_score(y_test , y_nb))\n",
    "print(\"Accuracy score:\",metrics.accuracy_score(y_test , y_nb))\n",
    "print(\"precision_score:\",metrics.precision_score(y_test , y_nb))\n",
    "print(\"recall_score:\",metrics.recall_score(y_test , y_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix: [[552  14]\n",
      " [ 42  52]]\n",
      "F1_ score : 0.65\n",
      "Accuracy score: 0.9151515151515152\n",
      "precision_score: 0.7878787878787878\n",
      "recall_score: 0.5531914893617021\n"
     ]
    }
   ],
   "source": [
    "from sklearn .tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 4)\n",
    "dt.fit(X_train,y_train)\n",
    "y_dt=dt.predict(X_test)\n",
    "print(\"confusion_matrix:\",confusion_matrix(y_test , y_dt))\n",
    "print(\"F1_ score :\",metrics.f1_score(y_test , y_dt))\n",
    "print(\"Accuracy score:\",metrics.accuracy_score(y_test , y_dt))\n",
    "print(\"precision_score:\",metrics.precision_score(y_test , y_dt))\n",
    "print(\"recall_score:\",metrics.recall_score(y_test , y_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix: [[564   2]\n",
      " [ 16  78]]\n",
      "F1_ score : 0.896551724137931\n",
      "Accuracy score: 0.9727272727272728\n",
      "precision_score: 0.975\n",
      "recall_score: 0.8297872340425532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 50)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred=knn.predict(X_test)\n",
    "print(\"confusion_matrix:\",confusion_matrix(y_test , rf_pred))\n",
    "print(\"F1_ score :\",metrics.f1_score(y_test , rf_pred))\n",
    "print(\"Accuracy score:\",metrics.accuracy_score(y_test , rf_pred))\n",
    "print(\"precision_score:\",metrics.precision_score(y_test , rf_pred))\n",
    "print(\"recall_score:\",metrics.recall_score(y_test , rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deep learning algorithm has the highest accuracy = 99%\n",
    "random forest has the second highest accuracy = 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
